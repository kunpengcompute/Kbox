Copyright (C) 2021. Huawei Technologies Co., Ltd. 

This program is free software; you can redistribute it and/or modify
it under the terms of the GNU General Public License version 2 and
only version 2 as published by the Free Software Foundation.

This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
GNU General Public License for more details.


diff -Nur a/binder/binder_alloc.c b/binder/binder_alloc.c
--- a/binder/binder_alloc.c	2020-10-31 16:29:01.046635602 +0800
+++ b/binder/binder_alloc.c	2020-10-31 16:30:48.610907048 +0800
@@ -46,7 +46,7 @@
 };
 static uint32_t binder_alloc_debug_mask = BINDER_DEBUG_USER_ERROR;
 
-module_param_named(debug_mask, binder_alloc_debug_mask,
+module_param_named(alloc_debug_mask, binder_alloc_debug_mask,
 		   uint, 0644);
 
 #define binder_alloc_debug(mask, x...) \
@@ -931,8 +931,8 @@
 	mm = alloc->vma_vm_mm;
 	if (!mmget_not_zero(mm))
 		goto err_mmget;
-	if (!down_write_trylock(&mm->mmap_sem))
-		goto err_down_write_mmap_sem_failed;
+	if (!down_read_trylock(&mm->mmap_sem))
+		goto err_down_read_mmap_sem_failed;
 	vma = binder_alloc_get_vma(alloc);
 
 	list_lru_isolate(lru, item);
@@ -945,7 +945,7 @@
 
 		trace_binder_unmap_user_end(alloc, index);
 	}
-	up_write(&mm->mmap_sem);
+	up_read(&mm->mmap_sem);
 	mmput(mm);
 
 	trace_binder_unmap_kernel_start(alloc, index);
@@ -959,7 +959,7 @@
 	mutex_unlock(&alloc->mutex);
 	return LRU_REMOVED_RETRY;
 
-err_down_write_mmap_sem_failed:
+err_down_read_mmap_sem_failed:
 	mmput_async(mm);
 err_mmget:
 err_page_already_freed:
@@ -1128,15 +1128,16 @@
 	return 0;
 }
 
-static void binder_alloc_do_buffer_copy(struct binder_alloc *alloc,
-					bool to_buffer,
-					struct binder_buffer *buffer,
-					binder_size_t buffer_offset,
-					void *ptr,
-					size_t bytes)
+static int binder_alloc_do_buffer_copy(struct binder_alloc *alloc,
+				       bool to_buffer,
+				       struct binder_buffer *buffer,
+				       binder_size_t buffer_offset,
+				       void *ptr,
+				       size_t bytes)
 {
 	/* All copies must be 32-bit aligned and 32-bit size */
-	BUG_ON(!check_buffer(alloc, buffer, buffer_offset, bytes));
+	if (!check_buffer(alloc, buffer, buffer_offset, bytes))
+		return -EINVAL;
 
 	while (bytes) {
 		unsigned long size;
@@ -1164,25 +1165,33 @@
 		ptr = ptr + size;
 		buffer_offset += size;
 	}
+	return 0;
 }
 
-void binder_alloc_copy_to_buffer(struct binder_alloc *alloc,
-				 struct binder_buffer *buffer,
-				 binder_size_t buffer_offset,
-				 void *src,
-				 size_t bytes)
+int binder_alloc_copy_to_buffer(struct binder_alloc *alloc,
+				struct binder_buffer *buffer,
+				binder_size_t buffer_offset,
+				void *src,
+				size_t bytes)
 {
-	binder_alloc_do_buffer_copy(alloc, true, buffer, buffer_offset,
-				    src, bytes);
+	return binder_alloc_do_buffer_copy(alloc, true, buffer, buffer_offset,
+					   src, bytes);
 }
 
-void binder_alloc_copy_from_buffer(struct binder_alloc *alloc,
-				   void *dest,
-				   struct binder_buffer *buffer,
-				   binder_size_t buffer_offset,
-				   size_t bytes)
+int binder_alloc_copy_from_buffer(struct binder_alloc *alloc,
+				  void *dest,
+				  struct binder_buffer *buffer,
+				  binder_size_t buffer_offset,
+				  size_t bytes)
+{
+	return binder_alloc_do_buffer_copy(alloc, false, buffer, buffer_offset,
+					   dest, bytes);
+}
+
+
+void binder_alloc_shrinker_exit(void)
 {
-	binder_alloc_do_buffer_copy(alloc, false, buffer, buffer_offset,
-				    dest, bytes);
+     unregister_shrinker(&binder_shrinker);
+     list_lru_destroy(&binder_alloc_lru);
 }
 
diff -Nur a/binder/binder_alloc.h b/binder/binder_alloc.h
--- a/binder/binder_alloc.h	2020-10-31 16:29:01.046635602 +0800
+++ b/binder/binder_alloc.h	2020-10-31 16:30:48.614907058 +0800
@@ -129,6 +129,7 @@
 						  int is_async);
 extern void binder_alloc_init(struct binder_alloc *alloc);
 extern int binder_alloc_shrinker_init(void);
+extern void binder_alloc_shrinker_exit(void);
 extern void binder_alloc_vma_close(struct binder_alloc *alloc);
 extern struct binder_buffer *
 binder_alloc_prepare_to_free(struct binder_alloc *alloc,
@@ -168,17 +169,17 @@
 				 const void __user *from,
 				 size_t bytes);
 
-void binder_alloc_copy_to_buffer(struct binder_alloc *alloc,
-				 struct binder_buffer *buffer,
-				 binder_size_t buffer_offset,
-				 void *src,
-				 size_t bytes);
-
-void binder_alloc_copy_from_buffer(struct binder_alloc *alloc,
-				   void *dest,
-				   struct binder_buffer *buffer,
-				   binder_size_t buffer_offset,
-				   size_t bytes);
+int binder_alloc_copy_to_buffer(struct binder_alloc *alloc,
+				struct binder_buffer *buffer,
+				binder_size_t buffer_offset,
+				void *src,
+				size_t bytes);
+
+int binder_alloc_copy_from_buffer(struct binder_alloc *alloc,
+				  void *dest,
+				  struct binder_buffer *buffer,
+				  binder_size_t buffer_offset,
+				  size_t bytes);
 
 #endif /* _LINUX_BINDER_ALLOC_H */
 
diff -Nur a/binder/binder.c b/binder/binder.c
--- a/binder/binder.c	2021-04-01 11:34:30.360000000 +0800
+++ b/binder/binder.c	2021-04-01 11:42:51.984000000 +0800
@@ -73,14 +73,16 @@
 #include <linux/ratelimit.h>
 #include <linux/syscalls.h>
 #include <linux/task_work.h>
-
-#include <uapi/linux/android/binder.h>
+#include <linux/eventpoll.h>
+// #include <uapi/linux/android/binder.h>
 
 #include <asm/cacheflush.h>
 
+#include "uapi/binder.h"
 #include "binder_alloc.h"
 #include "binder_internal.h"
 #include "binder_trace.h"
+typedef unsigned __bitwise __poll_t;
 
 static HLIST_HEAD(binder_deferred_list);
 static DEFINE_MUTEX(binder_deferred_lock);
@@ -96,6 +98,20 @@
 static struct dentry *binder_debugfs_dir_entry_proc;
 static atomic_t binder_last_id;
 
+#define DEFINE_SHOW_ATTRIBUTE(__name)                   \
+static int __name ## _open(struct inode *inode, struct file *file)  \
+{                                   \
+    return single_open(file, __name ## _show, inode->i_private);    \
+}                                   \
+                                    \
+static const struct file_operations __name ## _fops = {         \
+    .owner      = THIS_MODULE,                  \
+    .open       = __name ## _open,              \
+    .read       = seq_read,                 \
+    .llseek     = seq_lseek,                    \
+    .release    = single_release,               \
+}
+
 static int proc_show(struct seq_file *m, void *unused);
 DEFINE_SHOW_ATTRIBUTE(proc);
 
@@ -131,8 +147,8 @@
 	BINDER_DEBUG_FAILED_TRANSACTION | BINDER_DEBUG_DEAD_TRANSACTION;
 module_param_named(debug_mask, binder_debug_mask, uint, 0644);
 
-static char *binder_devices_param = CONFIG_ANDROID_BINDER_DEVICES;
-module_param_named(devices, binder_devices_param, charp, 0444);
+static int binder_devices_param = 1;
+module_param_named(num_devices, binder_devices_param, int, 0444);
 
 static DECLARE_WAIT_QUEUE_HEAD(binder_user_error_wait);
 static int binder_stop_on_user_error;
@@ -329,8 +345,6 @@
  *                        (invariant after initialized)
  * @min_priority:         minimum scheduling priority
  *                        (invariant after initialized)
- * @txn_security_ctx:     require sender's security context
- *                        (invariant after initialized)
  * @async_todo:           list of async work items
  *                        (protected by @proc->inner_lock)
  *
@@ -367,7 +381,6 @@
 		 * invariant after initialization
 		 */
 		u8 accept_fds:1;
-		u8 txn_security_ctx:1;
 		u8 min_priority;
 	};
 	bool has_async_transaction;
@@ -618,7 +631,6 @@
 	long	saved_priority;
 	kuid_t	sender_euid;
 	struct list_head fd_fixups;
-	binder_uintptr_t security_ctx;
 	/**
 	 * @lock:  protects @from, @to_proc, and @to_thread
 	 *
@@ -1176,7 +1188,6 @@
 	node->work.type = BINDER_WORK_NODE;
 	node->min_priority = flags & FLAT_BINDER_FLAG_PRIORITY_MASK;
 	node->accept_fds = !!(flags & FLAT_BINDER_FLAG_ACCEPTS_FDS);
-	node->txn_security_ctx = !!(flags & FLAT_BINDER_FLAG_TXN_SECURITY_CTX);
 	spin_lock_init(&node->lock);
 	INIT_LIST_HEAD(&node->work.entry);
 	INIT_LIST_HEAD(&node->async_todo);
@@ -1950,8 +1961,18 @@
 
 static void binder_free_transaction(struct binder_transaction *t)
 {
-	if (t->buffer)
-		t->buffer->transaction = NULL;
+	struct binder_proc *target_proc = t->to_proc;
+
+	if (target_proc) {
+		binder_inner_proc_lock(target_proc);
+		if (t->buffer)
+			t->buffer->transaction = NULL;
+		binder_inner_proc_unlock(target_proc);
+	}
+	/*
+	 * If the transaction has no target_proc, then
+	 * t->buffer->transaction has already been cleared.
+	 */
 	binder_free_txn_fixups(t);
 	kfree(t);
 	binder_stats_deleted(BINDER_STAT_TRANSACTION);
@@ -2058,10 +2079,9 @@
 
 	read_size = min_t(size_t, sizeof(*object), buffer->data_size - offset);
 	if (offset > buffer->data_size || read_size < sizeof(*hdr) ||
-	    !IS_ALIGNED(offset, sizeof(u32)))
+	    binder_alloc_copy_from_buffer(&proc->alloc, object, buffer,
+					  offset, read_size))
 		return 0;
-	binder_alloc_copy_from_buffer(&proc->alloc, object, buffer,
-				      offset, read_size);
 
 	/* Ok, now see if we read a complete object. */
 	hdr = &object->hdr;
@@ -2130,8 +2150,10 @@
 		return NULL;
 
 	buffer_offset = start_offset + sizeof(binder_size_t) * index;
-	binder_alloc_copy_from_buffer(&proc->alloc, &object_offset,
-				      b, buffer_offset, sizeof(object_offset));
+	if (binder_alloc_copy_from_buffer(&proc->alloc, &object_offset,
+					  b, buffer_offset,
+					  sizeof(object_offset)))
+		return NULL;
 	object_size = binder_get_object(proc, b, object_offset, object);
 	if (!object_size || object->hdr.type != BINDER_TYPE_PTR)
 		return NULL;
@@ -2211,10 +2233,12 @@
 			return false;
 		last_min_offset = last_bbo->parent_offset + sizeof(uintptr_t);
 		buffer_offset = objects_start_offset +
-			sizeof(binder_size_t) * last_bbo->parent,
-		binder_alloc_copy_from_buffer(&proc->alloc, &last_obj_offset,
-					      b, buffer_offset,
-					      sizeof(last_obj_offset));
+			sizeof(binder_size_t) * last_bbo->parent;
+		if (binder_alloc_copy_from_buffer(&proc->alloc,
+						  &last_obj_offset,
+						  b, buffer_offset,
+						  sizeof(last_obj_offset)))
+			return false;
 	}
 	return (fixup_offset >= last_min_offset);
 }
@@ -2255,6 +2279,47 @@
 	kfree(twcb);
 }
 
+static inline void __clear_open_fd(unsigned int fd, struct fdtable *fdt)
+{
+        __clear_bit(fd, fdt->open_fds);
+        __clear_bit(fd / BITS_PER_LONG, fdt->full_fds_bits);
+}
+
+static void __put_unused_fd(struct files_struct *files, unsigned int fd)
+{
+        struct fdtable *fdt = files_fdtable(files);
+        __clear_open_fd(fd, fdt);
+        if (fd < files->next_fd)
+                files->next_fd = fd;
+}
+
+static int my__close_fd_get_file(unsigned int fd, struct file **res) 
+{
+       struct files_struct *files = current->files;
+       struct file *file;
+       struct fdtable *fdt;
+
+       spin_lock(&files->file_lock);
+       fdt = files_fdtable(files);
+       if (fd >= fdt->max_fds)
+               goto out_unlock;
+       file = fdt->fd[fd];
+       if (!file)
+               goto out_unlock;
+       rcu_assign_pointer(fdt->fd[fd], NULL);
+       __put_unused_fd(files, fd);
+       spin_unlock(&files->file_lock);
+       get_file(file);
+       *res = file;
+       return filp_close(file, files);
+
+out_unlock:
+       spin_unlock(&files->file_lock);
+       *res = NULL;
+       return -ENOENT;
+}
+
+
 /**
  * binder_deferred_fd_close() - schedule a close for the given file-descriptor
  * @fd:		file-descriptor to close
@@ -2270,7 +2335,7 @@
 	if (!twcb)
 		return;
 	init_task_work(&twcb->twork, binder_do_fd_close);
-	__close_fd_get_file(fd, &twcb->file);
+	my__close_fd_get_file(fd, &twcb->file);
 	if (twcb->file)
 		task_work_add(current, &twcb->twork, true);
 	else
@@ -2300,15 +2365,15 @@
 	for (buffer_offset = off_start_offset; buffer_offset < off_end_offset;
 	     buffer_offset += sizeof(binder_size_t)) {
 		struct binder_object_header *hdr;
-		size_t object_size;
+		size_t object_size = 0;
 		struct binder_object object;
 		binder_size_t object_offset;
 
-		binder_alloc_copy_from_buffer(&proc->alloc, &object_offset,
-					      buffer, buffer_offset,
-					      sizeof(object_offset));
-		object_size = binder_get_object(proc, buffer,
-						object_offset, &object);
+		if (!binder_alloc_copy_from_buffer(&proc->alloc, &object_offset,
+						   buffer, buffer_offset,
+						   sizeof(object_offset)))
+			object_size = binder_get_object(proc, buffer,
+							object_offset, &object);
 		if (object_size == 0) {
 			pr_err("transaction release %d bad object at offset %lld, size %zd\n",
 			       debug_id, (u64)object_offset, buffer->data_size);
@@ -2431,15 +2496,16 @@
 			for (fd_index = 0; fd_index < fda->num_fds;
 			     fd_index++) {
 				u32 fd;
+				int err;
 				binder_size_t offset = fda_offset +
 					fd_index * sizeof(fd);
 
-				binder_alloc_copy_from_buffer(&proc->alloc,
-							      &fd,
-							      buffer,
-							      offset,
-							      sizeof(fd));
-				binder_deferred_fd_close(fd);
+				err = binder_alloc_copy_from_buffer(
+						&proc->alloc, &fd, buffer,
+						offset, sizeof(fd));
+				WARN_ON(err);
+				if (!err)
+					binder_deferred_fd_close(fd);
 			}
 		} break;
 		default:
@@ -2682,11 +2748,12 @@
 		int ret;
 		binder_size_t offset = fda_offset + fdi * sizeof(fd);
 
-		binder_alloc_copy_from_buffer(&target_proc->alloc,
-					      &fd, t->buffer,
-					      offset, sizeof(fd));
-		ret = binder_translate_fd(fd, offset, t, thread,
-					  in_reply_to);
+		ret = binder_alloc_copy_from_buffer(&target_proc->alloc,
+						    &fd, t->buffer,
+						    offset, sizeof(fd));
+		if (!ret)
+			ret = binder_translate_fd(fd, offset, t, thread,
+						  in_reply_to);
 		if (ret < 0)
 			return ret;
 	}
@@ -2739,8 +2806,12 @@
 	}
 	buffer_offset = bp->parent_offset +
 			(uintptr_t)parent->buffer - (uintptr_t)b->user_data;
-	binder_alloc_copy_to_buffer(&target_proc->alloc, b, buffer_offset,
-				    &bp->buffer, sizeof(bp->buffer));
+	if (binder_alloc_copy_to_buffer(&target_proc->alloc, b, buffer_offset,
+					&bp->buffer, sizeof(bp->buffer))) {
+		binder_user_error("%d:%d got transaction with invalid parent offset\n",
+				  proc->pid, thread->pid);
+		return -EINVAL;
+	}
 
 	return 0;
 }
@@ -2875,8 +2946,6 @@
 	binder_size_t last_fixup_min_off = 0;
 	struct binder_context *context = proc->context;
 	int t_debug_id = atomic_inc_return(&binder_last_id);
-	char *secctx = NULL;
-	u32 secctx_sz = 0;
 
 	e = binder_transaction_log_add(&binder_transaction_log);
 	e->debug_id = t_debug_id;
@@ -2978,7 +3047,7 @@
 			else
 				return_error = BR_DEAD_REPLY;
 			mutex_unlock(&context->context_mgr_node_lock);
-			if (target_node && target_proc == proc) {
+			if (target_node && target_proc->pid == proc->pid) {
 				binder_user_error("%d:%d got transaction to context manager from process owning it\n",
 						  proc->pid, thread->pid);
 				return_error = BR_FAILED_REPLY;
@@ -3119,20 +3188,6 @@
 	t->flags = tr->flags;
 	t->priority = task_nice(current);
 
-	if (target_node && target_node->txn_security_ctx) {
-		u32 secid;
-
-		security_task_getsecid(proc->tsk, &secid);
-		ret = security_secid_to_secctx(secid, &secctx, &secctx_sz);
-		if (ret) {
-			return_error = BR_FAILED_REPLY;
-			return_error_param = ret;
-			return_error_line = __LINE__;
-			goto err_get_secctx_failed;
-		}
-		extra_buffers_size += ALIGN(secctx_sz, sizeof(u64));
-	}
-
 	trace_binder_transaction(reply, t, target_node);
 
 	t->buffer = binder_alloc_new_buf(&target_proc->alloc, tr->data_size,
@@ -3149,19 +3204,6 @@
 		t->buffer = NULL;
 		goto err_binder_alloc_buf_failed;
 	}
-	if (secctx) {
-		size_t buf_offset = ALIGN(tr->data_size, sizeof(void *)) +
-				    ALIGN(tr->offsets_size, sizeof(void *)) +
-				    ALIGN(extra_buffers_size, sizeof(void *)) -
-				    ALIGN(secctx_sz, sizeof(u64));
-
-		t->security_ctx = (uintptr_t)t->buffer->user_data + buf_offset;
-		binder_alloc_copy_to_buffer(&target_proc->alloc,
-					    t->buffer, buf_offset,
-					    secctx, secctx_sz);
-		security_release_secctx(secctx, secctx_sz);
-		secctx = NULL;
-	}
 	t->buffer->debug_id = t->debug_id;
 	t->buffer->transaction = t;
 	t->buffer->target_node = target_node;
@@ -3224,11 +3266,16 @@
 		struct binder_object object;
 		binder_size_t object_offset;
 
-		binder_alloc_copy_from_buffer(&target_proc->alloc,
-					      &object_offset,
-					      t->buffer,
-					      buffer_offset,
-					      sizeof(object_offset));
+		if (binder_alloc_copy_from_buffer(&target_proc->alloc,
+						  &object_offset,
+						  t->buffer,
+						  buffer_offset,
+						  sizeof(object_offset))) {
+			return_error = BR_FAILED_REPLY;
+			return_error_param = -EINVAL;
+			return_error_line = __LINE__;
+			goto err_bad_offset;
+		}
 		object_size = binder_get_object(target_proc, t->buffer,
 						object_offset, &object);
 		if (object_size == 0 || object_offset < off_min) {
@@ -3252,15 +3299,17 @@
 
 			fp = to_flat_binder_object(hdr);
 			ret = binder_translate_binder(fp, t, thread);
-			if (ret < 0) {
+
+			if (ret < 0 ||
+			    binder_alloc_copy_to_buffer(&target_proc->alloc,
+							t->buffer,
+							object_offset,
+							fp, sizeof(*fp))) {
 				return_error = BR_FAILED_REPLY;
 				return_error_param = ret;
 				return_error_line = __LINE__;
 				goto err_translate_failed;
 			}
-			binder_alloc_copy_to_buffer(&target_proc->alloc,
-						    t->buffer, object_offset,
-						    fp, sizeof(*fp));
 		} break;
 		case BINDER_TYPE_HANDLE:
 		case BINDER_TYPE_WEAK_HANDLE: {
@@ -3268,15 +3317,16 @@
 
 			fp = to_flat_binder_object(hdr);
 			ret = binder_translate_handle(fp, t, thread);
-			if (ret < 0) {
+			if (ret < 0 ||
+			    binder_alloc_copy_to_buffer(&target_proc->alloc,
+							t->buffer,
+							object_offset,
+							fp, sizeof(*fp))) {
 				return_error = BR_FAILED_REPLY;
 				return_error_param = ret;
 				return_error_line = __LINE__;
 				goto err_translate_failed;
 			}
-			binder_alloc_copy_to_buffer(&target_proc->alloc,
-						    t->buffer, object_offset,
-						    fp, sizeof(*fp));
 		} break;
 
 		case BINDER_TYPE_FD: {
@@ -3286,16 +3336,17 @@
 			int ret = binder_translate_fd(fp->fd, fd_offset, t,
 						      thread, in_reply_to);
 
-			if (ret < 0) {
+			fp->pad_binder = 0;
+			if (ret < 0 ||
+			    binder_alloc_copy_to_buffer(&target_proc->alloc,
+							t->buffer,
+							object_offset,
+							fp, sizeof(*fp))) {
 				return_error = BR_FAILED_REPLY;
 				return_error_param = ret;
 				return_error_line = __LINE__;
 				goto err_translate_failed;
 			}
-			fp->pad_binder = 0;
-			binder_alloc_copy_to_buffer(&target_proc->alloc,
-						    t->buffer, object_offset,
-						    fp, sizeof(*fp));
 		} break;
 		case BINDER_TYPE_FDA: {
 			struct binder_object ptr_object;
@@ -3383,15 +3434,16 @@
 						  num_valid,
 						  last_fixup_obj_off,
 						  last_fixup_min_off);
-			if (ret < 0) {
+			if (ret < 0 ||
+			    binder_alloc_copy_to_buffer(&target_proc->alloc,
+							t->buffer,
+							object_offset,
+							bp, sizeof(*bp))) {
 				return_error = BR_FAILED_REPLY;
 				return_error_param = ret;
 				return_error_line = __LINE__;
 				goto err_translate_failed;
 			}
-			binder_alloc_copy_to_buffer(&target_proc->alloc,
-						    t->buffer, object_offset,
-						    bp, sizeof(*bp));
 			last_fixup_obj_off = object_offset;
 			last_fixup_min_off = 0;
 		} break;
@@ -3480,9 +3532,6 @@
 	t->buffer->transaction = NULL;
 	binder_alloc_free_buf(&target_proc->alloc, t->buffer);
 err_binder_alloc_buf_failed:
-	if (secctx)
-		security_release_secctx(secctx, secctx_sz);
-err_get_secctx_failed:
 	kfree(tcomplete);
 	binder_stats_deleted(BINDER_STAT_TRANSACTION_COMPLETE);
 err_alloc_tcomplete_failed:
@@ -3550,10 +3599,12 @@
 static void
 binder_free_buf(struct binder_proc *proc, struct binder_buffer *buffer)
 {
+	binder_inner_proc_lock(proc);
 	if (buffer->transaction) {
 		buffer->transaction->buffer = NULL;
 		buffer->transaction = NULL;
 	}
+	binder_inner_proc_unlock(proc);
 	if (buffer->async_transaction && buffer->target_node) {
 		struct binder_node *buf_node;
 		struct binder_work *w;
@@ -4127,20 +4178,27 @@
 		trace_binder_transaction_fd_recv(t, fd, fixup->offset);
 		fd_install(fd, fixup->file);
 		fixup->file = NULL;
-		binder_alloc_copy_to_buffer(&proc->alloc, t->buffer,
-					    fixup->offset, &fd,
-					    sizeof(u32));
+		if (binder_alloc_copy_to_buffer(&proc->alloc, t->buffer,
+						fixup->offset, &fd,
+						sizeof(u32))) {
+			ret = -EINVAL;
+			break;
+		}
 	}
 	list_for_each_entry_safe(fixup, tmp, &t->fd_fixups, fixup_entry) {
 		if (fixup->file) {
 			fput(fixup->file);
 		} else if (ret) {
 			u32 fd;
+			int err;
 
-			binder_alloc_copy_from_buffer(&proc->alloc, &fd,
-						      t->buffer, fixup->offset,
-						      sizeof(fd));
-			binder_deferred_fd_close(fd);
+			err = binder_alloc_copy_from_buffer(&proc->alloc, &fd,
+							    t->buffer,
+							    fixup->offset,
+							    sizeof(fd));
+			WARN_ON(err);
+			if (!err)
+				binder_deferred_fd_close(fd);
 		}
 		list_del(&fixup->fixup_entry);
 		kfree(fixup);
@@ -4202,13 +4260,11 @@
 
 	while (1) {
 		uint32_t cmd;
-		struct binder_transaction_data_secctx tr;
-		struct binder_transaction_data *trd = &tr.transaction_data;
+		struct binder_transaction_data tr;
 		struct binder_work *w = NULL;
 		struct list_head *list = NULL;
 		struct binder_transaction *t = NULL;
 		struct binder_thread *t_from;
-		size_t trsize = sizeof(*trd);
 
 		binder_inner_proc_lock(proc);
 		if (!binder_worklist_empty_ilocked(&thread->todo))
@@ -4255,6 +4311,8 @@
 		case BINDER_WORK_TRANSACTION_COMPLETE: {
 			binder_inner_proc_unlock(proc);
 			cmd = BR_TRANSACTION_COMPLETE;
+			kfree(w);
+			binder_stats_deleted(BINDER_STAT_TRANSACTION_COMPLETE);
 			if (put_user(cmd, (uint32_t __user *)ptr))
 				return -EFAULT;
 			ptr += sizeof(uint32_t);
@@ -4263,8 +4321,6 @@
 			binder_debug(BINDER_DEBUG_TRANSACTION_COMPLETE,
 				     "%d:%d BR_TRANSACTION_COMPLETE\n",
 				     proc->pid, thread->pid);
-			kfree(w);
-			binder_stats_deleted(BINDER_STAT_TRANSACTION_COMPLETE);
 		} break;
 		case BINDER_WORK_NODE: {
 			struct binder_node *node = container_of(w, struct binder_node, work);
@@ -4408,8 +4464,8 @@
 		if (t->buffer->target_node) {
 			struct binder_node *target_node = t->buffer->target_node;
 
-			trd->target.ptr = target_node->ptr;
-			trd->cookie =  target_node->cookie;
+			tr.target.ptr = target_node->ptr;
+			tr.cookie =  target_node->cookie;
 			t->saved_priority = task_nice(current);
 			if (t->priority < target_node->min_priority &&
 			    !(t->flags & TF_ONE_WAY))
@@ -4419,23 +4475,22 @@
 				binder_set_nice(target_node->min_priority);
 			cmd = BR_TRANSACTION;
 		} else {
-			trd->target.ptr = 0;
-			trd->cookie = 0;
+			tr.target.ptr = 0;
+			tr.cookie = 0;
 			cmd = BR_REPLY;
 		}
-		trd->code = t->code;
-		trd->flags = t->flags;
-		trd->sender_euid = from_kuid(current_user_ns(), t->sender_euid);
+		tr.code = t->code;
+		tr.flags = t->flags;
+		tr.sender_euid = from_kuid(current_user_ns(), t->sender_euid);
 
 		t_from = binder_get_txn_from(t);
 		if (t_from) {
 			struct task_struct *sender = t_from->proc->tsk;
 
-			trd->sender_pid =
-				task_tgid_nr_ns(sender,
-						task_active_pid_ns(current));
+			tr.sender_pid = task_tgid_nr_ns(sender,
+							task_active_pid_ns(current));
 		} else {
-			trd->sender_pid = 0;
+			tr.sender_pid = 0;
 		}
 
 		ret = binder_apply_fd_fixups(proc, t);
@@ -4466,18 +4521,13 @@
 			}
 			continue;
 		}
-		trd->data_size = t->buffer->data_size;
-		trd->offsets_size = t->buffer->offsets_size;
-		trd->data.ptr.buffer = (uintptr_t)t->buffer->user_data;
-		trd->data.ptr.offsets = trd->data.ptr.buffer +
+		tr.data_size = t->buffer->data_size;
+		tr.offsets_size = t->buffer->offsets_size;
+		tr.data.ptr.buffer = (uintptr_t)t->buffer->user_data;
+		tr.data.ptr.offsets = tr.data.ptr.buffer +
 					ALIGN(t->buffer->data_size,
 					    sizeof(void *));
 
-		tr.secctx = t->security_ctx;
-		if (t->security_ctx) {
-			cmd = BR_TRANSACTION_SEC_CTX;
-			trsize = sizeof(tr);
-		}
 		if (put_user(cmd, (uint32_t __user *)ptr)) {
 			if (t_from)
 				binder_thread_dec_tmpref(t_from);
@@ -4488,7 +4538,7 @@
 			return -EFAULT;
 		}
 		ptr += sizeof(uint32_t);
-		if (copy_to_user(ptr, &tr, trsize)) {
+		if (copy_to_user(ptr, &tr, sizeof(tr))) {
 			if (t_from)
 				binder_thread_dec_tmpref(t_from);
 
@@ -4497,7 +4547,7 @@
 
 			return -EFAULT;
 		}
-		ptr += trsize;
+		ptr += sizeof(tr);
 
 		trace_binder_transaction_received(t);
 		binder_stat_br(proc, thread, cmd);
@@ -4505,18 +4555,16 @@
 			     "%d:%d %s %d %d:%d, cmd %d size %zd-%zd ptr %016llx-%016llx\n",
 			     proc->pid, thread->pid,
 			     (cmd == BR_TRANSACTION) ? "BR_TRANSACTION" :
-				(cmd == BR_TRANSACTION_SEC_CTX) ?
-				     "BR_TRANSACTION_SEC_CTX" : "BR_REPLY",
+			     "BR_REPLY",
 			     t->debug_id, t_from ? t_from->proc->pid : 0,
 			     t_from ? t_from->pid : 0, cmd,
 			     t->buffer->data_size, t->buffer->offsets_size,
-			     (u64)trd->data.ptr.buffer,
-			     (u64)trd->data.ptr.offsets);
+			     (u64)tr.data.ptr.buffer, (u64)tr.data.ptr.offsets);
 
 		if (t_from)
 			binder_thread_dec_tmpref(t_from);
 		t->buffer->allow_user_free = 1;
-		if (cmd != BR_REPLY && !(t->flags & TF_ONE_WAY)) {
+		if (cmd == BR_TRANSACTION && !(t->flags & TF_ONE_WAY)) {
 			binder_inner_proc_lock(thread->proc);
 			t->to_parent = thread->transaction_stack;
 			t->to_thread = thread;
@@ -4864,8 +4912,7 @@
 	return ret;
 }
 
-static int binder_ioctl_set_ctx_mgr(struct file *filp,
-				    struct flat_binder_object *fbo)
+static int binder_ioctl_set_ctx_mgr(struct file *filp)
 {
 	int ret = 0;
 	struct binder_proc *proc = filp->private_data;
@@ -4894,7 +4941,7 @@
 	} else {
 		context->binder_context_mgr_uid = curr_euid;
 	}
-	new_node = binder_new_node(proc, fbo);
+	new_node = binder_new_node(proc, NULL);
 	if (!new_node) {
 		ret = -ENOMEM;
 		goto out;
@@ -5017,20 +5064,8 @@
 		binder_inner_proc_unlock(proc);
 		break;
 	}
-	case BINDER_SET_CONTEXT_MGR_EXT: {
-		struct flat_binder_object fbo;
-
-		if (copy_from_user(&fbo, ubuf, sizeof(fbo))) {
-			ret = -EINVAL;
-			goto err;
-		}
-		ret = binder_ioctl_set_ctx_mgr(filp, &fbo);
-		if (ret)
-			goto err;
-		break;
-	}
 	case BINDER_SET_CONTEXT_MGR:
-		ret = binder_ioctl_set_ctx_mgr(filp, NULL);
+		ret = binder_ioctl_set_ctx_mgr(filp);
 		if (ret)
 			goto err;
 		break;
@@ -5183,6 +5218,8 @@
 
 static int binder_open(struct inode *nodp, struct file *filp)
 {
+	int minor = iminor(nodp);
+	struct hlist_node *tmp;
 	struct binder_proc *proc;
 	struct binder_device *binder_dev;
 
@@ -5199,11 +5236,15 @@
 	INIT_LIST_HEAD(&proc->todo);
 	proc->default_priority = task_nice(current);
 	/* binderfs stashes devices in i_private */
-	if (is_binderfs_device(nodp))
-		binder_dev = nodp->i_private;
-	else
-		binder_dev = container_of(filp->private_data,
-					  struct binder_device, miscdev);
+	hlist_for_each_entry_safe(binder_dev, tmp, &binder_devices, hlist) {
+		if (MINOR(binder_dev->cdev.dev) == minor) {
+			break;
+		}
+		binder_dev = NULL;
+	}
+	if (!binder_dev) 
+		BUG();
+	filp->private_data = &binder_dev->class_dev;
 	proc->context = &binder_dev->context;
 	binder_alloc_init(&proc->alloc);
 
@@ -6010,25 +6051,68 @@
 DEFINE_SHOW_ATTRIBUTE(transactions);
 DEFINE_SHOW_ATTRIBUTE(transaction_log);
 
-static int __init init_binder_device(const char *name)
+static struct class *binder_class;
+static void binder_device_release(struct device *dev) {
+
+}
+
+static int __init init_binder_device(int idx)
 {
 	int ret;
+	char *name;
+	dev_t devnr;
 	struct binder_device *binder_device;
 
+	/*
+	 * strlen("binder");
+	 * +
+	 * max length of 64 bit int as string
+	 */
+	char numstr[6 + 21] = "binder";
 	binder_device = kzalloc(sizeof(*binder_device), GFP_KERNEL);
 	if (!binder_device)
 		return -ENOMEM;
 
-	binder_device->miscdev.fops = &binder_fops;
-	binder_device->miscdev.minor = MISC_DYNAMIC_MINOR;
-	binder_device->miscdev.name = name;
+	cdev_init(&binder_device->cdev, &binder_fops);
+	binder_device->cdev.owner = THIS_MODULE;
+
+	devnr = MKDEV(BINDER_DKMS_MAJOR, idx);
+	ret = cdev_add(&binder_device->cdev, devnr, 1);
+	if (ret) {
+		kfree(binder_device);
+		return ret;
+	}
+
+	if (binder_devices_param > 1) {
+		ret = snprintf(numstr, sizeof(numstr), "aosp9_binder%d", idx);
+	}
 
+	if (ret < 0 || (size_t)ret >= sizeof(numstr)) {
+		cdev_del(&binder_device->cdev);
+		kfree(binder_device);
+		return -EIO;		
+	}
+	name = kzalloc(strlen(numstr) + 1, GFP_KERNEL);
+	if (!name) {
+		cdev_del(&binder_device->cdev);
+		kfree(binder_device);
+		return -ENOMEM;
+	}
+	strcpy(name, numstr);
 	binder_device->context.binder_context_mgr_uid = INVALID_UID;
 	binder_device->context.name = name;
 	mutex_init(&binder_device->context.context_mgr_node_lock);
 
-	ret = misc_register(&binder_device->miscdev);
+	binder_device->class_dev.devt = binder_device->cdev.dev;
+	binder_device->class_dev.class = binder_class;
+	binder_device->class_dev.release = binder_device_release;
+
+	dev_set_name(&binder_device->class_dev, "%s", name);
+
+	ret = device_register(&binder_device->class_dev);
 	if (ret < 0) {
+		kfree(name);
+		cdev_del(&binder_device->cdev);
 		kfree(binder_device);
 		return ret;
 	}
@@ -6038,14 +6122,15 @@
 	return ret;
 }
 
-static int __init binder_init(void)
+static int __init aosp9_binder_init(void)
 {
-	int ret;
-	char *device_name, *device_tmp;
+	int i, ret;
 	struct binder_device *device;
 	struct hlist_node *tmp;
-	char *device_names = NULL;
 
+	if (binder_devices_param <= 0 || binder_devices_param > BINDER_DKMS_MAX_MINOR) {
+		return -EINVAL;
+	}
 	ret = binder_alloc_shrinker_init();
 	if (ret)
 		return ret;
@@ -6053,7 +6138,7 @@
 	atomic_set(&binder_transaction_log.cur, ~0U);
 	atomic_set(&binder_transaction_log_failed.cur, ~0U);
 
-	binder_debugfs_dir_entry_root = debugfs_create_dir("binder", NULL);
+	binder_debugfs_dir_entry_root = debugfs_create_dir("aosp9_binder", NULL);
 	if (binder_debugfs_dir_entry_root)
 		binder_debugfs_dir_entry_proc = debugfs_create_dir("proc",
 						 binder_debugfs_dir_entry_root);
@@ -6086,47 +6171,66 @@
 				    &transaction_log_fops);
 	}
 
-	if (strcmp(binder_devices_param, "") != 0) {
-		/*
-		* Copy the module_parameter string, because we don't want to
-		* tokenize it in-place.
-		 */
-		device_names = kstrdup(binder_devices_param, GFP_KERNEL);
-		if (!device_names) {
-			ret = -ENOMEM;
-			goto err_alloc_device_names_failed;
-		}
-
-		device_tmp = device_names;
-		while ((device_name = strsep(&device_tmp, ","))) {
-			ret = init_binder_device(device_name);
-			if (ret)
-				goto err_init_binder_device_failed;
-		}
+	ret = register_chrdev_region(MKDEV(BINDER_DKMS_MAJOR, 0), BINDER_DKMS_MAX_MINOR, "aosp9_binder");
+	if (ret) {
+		goto on_error_remove_debugfs;
 	}
 
-	ret = init_binderfs();
-	if (ret)
-		goto err_init_binder_device_failed;
+	binder_class = class_create(THIS_MODULE, "aosp9_binder");
+	if (IS_ERR(binder_class)) {
+		goto on_error_unregister_chrdev_region;
+	}
 
+	for (i = 0; i < binder_devices_param; i++) {
+		ret = init_binder_device(i);
+		if (ret) {
+			goto err_init_binder_device_failed;
+		}
+	}
 	return ret;
 
 err_init_binder_device_failed:
 	hlist_for_each_entry_safe(device, tmp, &binder_devices, hlist) {
-		misc_deregister(&device->miscdev);
+		cdev_del(&device->cdev);
+		device_unregister(&device->class_dev);
+		kfree(device->context.name);
 		hlist_del(&device->hlist);
 		kfree(device);
 	}
+	class_destroy(binder_class);
 
-	kfree(device_names);
+on_error_unregister_chrdev_region:
+	unregister_chrdev_region(MKDEV(BINDER_DKMS_MAJOR, 0), BINDER_DKMS_MAX_MINOR);
 
-err_alloc_device_names_failed:
+on_error_remove_debugfs:
 	debugfs_remove_recursive(binder_debugfs_dir_entry_root);
+	binder_alloc_shrinker_exit();
+	return -1;
+}
 
-	return ret;
+static void __exit aosp9_binder_exit(void)
+{
+	struct binder_device *device;
+	struct hlist_node *tmp;
+
+	hlist_for_each_entry_safe(device, tmp, &binder_devices, hlist) {
+		cdev_del(&device->cdev);
+		device_unregister(&device->class_dev);
+		kfree(device->context.name);
+		hlist_del(&device->hlist);
+		kfree(device);
+	}
+
+	class_destroy(binder_class);
+
+	unregister_chrdev_region(MKDEV(BINDER_DKMS_MAJOR, 0), BINDER_DKMS_MAX_MINOR);
+
+	debugfs_remove_recursive(binder_debugfs_dir_entry_root);
+	binder_alloc_shrinker_exit();
 }
 
-device_initcall(binder_init);
+module_init(aosp9_binder_init);
+module_exit(aosp9_binder_exit);
 
 #define CREATE_TRACE_POINTS
 #include "binder_trace.h"
diff -Nur a/binder/binder_internal.h b/binder/binder_internal.h
--- a/binder/binder_internal.h	2020-10-31 16:29:01.046635602 +0800
+++ b/binder/binder_internal.h	2020-10-31 16:30:48.642907129 +0800
@@ -6,7 +6,7 @@
 #include <linux/export.h>
 #include <linux/fs.h>
 #include <linux/list.h>
-#include <linux/miscdevice.h>
+#include <linux/cdev.h>
 #include <linux/mutex.h>
 #include <linux/stddef.h>
 #include <linux/types.h>
@@ -25,34 +25,17 @@
  *                  CONFIG_ANDROID_BINDER_DEVICES)
  * @miscdev:        information about a binder character device node
  * @context:        binder context information
- * @binderfs_inode: This is the inode of the root dentry of the super block
- *                  belonging to a binderfs mount.
  */
 struct binder_device {
 	struct hlist_node hlist;
-	struct miscdevice miscdev;
+	struct cdev cdev;
+	struct device class_dev;
 	struct binder_context context;
-	struct inode *binderfs_inode;
 };
 
 extern const struct file_operations binder_fops;
 
-#ifdef CONFIG_ANDROID_BINDERFS
-extern bool is_binderfs_device(const struct inode *inode);
-#else
-static inline bool is_binderfs_device(const struct inode *inode)
-{
-	return false;
-}
-#endif
-
-#ifdef CONFIG_ANDROID_BINDERFS
-extern int __init init_binderfs(void);
-#else
-static inline int __init init_binderfs(void)
-{
-	return 0;
-}
-#endif
+#define BINDER_DKMS_MAJOR 501
+#define BINDER_DKMS_MAX_MINOR 1024
 
 #endif /* _LINUX_BINDER_INTERNAL_H */
diff -Nur a/binder/binder_trace.h b/binder/binder_trace.h
--- a/binder/binder_trace.h	2020-10-31 16:29:01.046635602 +0800
+++ b/binder/binder_trace.h	2020-10-31 16:30:48.642907129 +0800
@@ -13,7 +13,7 @@
  */
 
 #undef TRACE_SYSTEM
-#define TRACE_SYSTEM binder
+#define TRACE_SYSTEM aosp9_binder
 
 #if !defined(_BINDER_TRACE_H) || defined(TRACE_HEADER_MULTI_READ)
 #define _BINDER_TRACE_H
diff -Nur a/binder/deps.c b/binder/deps.c
--- a/binder/deps.c	1970-01-01 08:00:00.000000000 +0800
+++ b/binder/deps.c	2020-10-31 16:30:48.642907129 +0800
@@ -0,0 +1,162 @@
+#include <linux/sched.h>
+#include <linux/file.h>
+#include <linux/fdtable.h>
+#include <linux/atomic.h>
+#include <linux/mm.h>
+#include <linux/slab.h>
+#include <linux/spinlock.h>
+#include <linux/kallsyms.h>
+#include <linux/version.h>
+
+static struct vm_struct *(*get_vm_area_ptr)(unsigned long, unsigned long) = NULL;
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 11, 0)
+static void (*zap_page_range_ptr)(struct vm_area_struct *, unsigned long, unsigned long) = NULL;
+#else
+static void (*zap_page_range_ptr)(struct vm_area_struct *, unsigned long, unsigned long, struct zap_details *) = NULL;
+#endif
+static int (*map_kernel_range_noflush_ptr)(unsigned long start, unsigned long size, pgprot_t prot, struct page **pages) = NULL;
+static void (*unmap_kernel_range_ptr)(unsigned long, unsigned long) = NULL;
+static struct files_struct *(*get_files_struct_ptr)(struct task_struct *) = NULL;
+static void (*put_files_struct_ptr)(struct files_struct *) = NULL;
+static struct sighand_struct *(*__lock_task_sighand_ptr)(struct task_struct *, unsigned long *) = NULL;
+static int (*__alloc_fd_ptr)(struct files_struct *files, unsigned start, unsigned end, unsigned flags) = NULL;
+static void (*__fd_install_ptr)(struct files_struct *files, unsigned int fd, struct file *file) = NULL;
+static int (*__close_fd_ptr)(struct files_struct *files, unsigned int fd) = NULL;
+static int (*can_nice_ptr)(const struct task_struct *, const int) = NULL;
+static int (*security_binder_set_context_mgr_ptr)(struct task_struct *mgr) = NULL;
+static int (*security_binder_transaction_ptr)(struct task_struct *from, struct task_struct *to) = NULL;
+static int (*security_binder_transfer_binder_ptr)(struct task_struct *from, struct task_struct *to) = NULL;
+static int (*security_binder_transfer_file_ptr)(struct task_struct *from, struct task_struct *to, struct file *file) = NULL;
+static void (*mmput_async_ptr)(struct mm_struct *mm) = NULL;
+static int (*task_work_add_ptr)(struct task_struct *task, struct callback_head *twork, bool notify) = NULL;
+
+int task_work_add(struct task_struct *task, struct callback_head *twork, bool notify) {
+	if (!task_work_add_ptr) {
+		task_work_add_ptr = kallsyms_lookup_name("task_work_add");
+	}
+	return task_work_add_ptr(task, twork, notify);
+}
+
+bool has_capability_noaudit(struct task_struct *t, int cap) {
+	return true;
+}
+void mmput_async(struct mm_struct *mm) {
+	if (!mmput_async_ptr) {
+		mmput_async_ptr = kallsyms_lookup_name("mmput_async");
+	}
+	mmput_async_ptr(mm);
+	
+}
+
+struct vm_struct *get_vm_area(unsigned long size, unsigned long flags)
+{
+	if (!get_vm_area_ptr)
+		get_vm_area_ptr = kallsyms_lookup_name("get_vm_area");
+	return get_vm_area_ptr(size, flags);
+}
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 11, 0)
+void zap_page_range(struct vm_area_struct *vma, unsigned long address, unsigned long size)
+#else
+void zap_page_range(struct vm_area_struct *vma, unsigned long address, unsigned long size, struct zap_details *details)
+#endif
+{
+	if (!zap_page_range_ptr)
+		zap_page_range_ptr = kallsyms_lookup_name("zap_page_range");
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(4, 11, 0)
+	zap_page_range_ptr(vma, address, size);
+#else
+	zap_page_range_ptr(vma, address, size, details);
+#endif
+}
+
+int map_kernel_range_noflush(unsigned long start, unsigned long size, pgprot_t prot, struct page **pages)
+{
+	if (!map_kernel_range_noflush_ptr)
+		map_kernel_range_noflush_ptr = kallsyms_lookup_name("map_kernel_range_noflush");
+	return map_kernel_range_noflush_ptr(start, size, prot, pages);
+}
+
+void unmap_kernel_range(unsigned long addr, unsigned long size)
+{
+	if (!unmap_kernel_range_ptr)
+		unmap_kernel_range_ptr = kallsyms_lookup_name("unmap_kernel_range");
+	unmap_kernel_range_ptr(addr, size);
+}
+
+struct files_struct *get_files_struct(struct task_struct *task)
+{
+	if (!get_files_struct_ptr)
+		get_files_struct_ptr = kallsyms_lookup_name("get_files_struct");
+	return get_files_struct_ptr(task);
+}
+
+void put_files_struct(struct files_struct *files)
+{
+	if (!put_files_struct_ptr)
+		put_files_struct_ptr = kallsyms_lookup_name("put_files_struct");
+	put_files_struct_ptr(files);
+}
+
+struct sighand_struct *__lock_task_sighand(struct task_struct *tsk, unsigned long *flags)
+{
+	if (!__lock_task_sighand_ptr)
+		__lock_task_sighand_ptr = kallsyms_lookup_name("__lock_task_sighand");
+	return __lock_task_sighand_ptr(tsk, flags);
+}
+
+int __alloc_fd(struct files_struct *files, unsigned start, unsigned end, unsigned flags)
+{
+	if (!__alloc_fd_ptr)
+		__alloc_fd_ptr = kallsyms_lookup_name("__alloc_fd");
+	return __alloc_fd_ptr(files, start, end, flags);
+}
+
+void __fd_install(struct files_struct *files, unsigned int fd, struct file *file)
+{
+	if (!__fd_install_ptr)
+		__fd_install_ptr = kallsyms_lookup_name("__fd_install");
+	__fd_install_ptr(files, fd, file);
+}
+
+int __close_fd(struct files_struct *files, unsigned int fd)
+{
+	if (!__close_fd_ptr)
+		__close_fd_ptr = kallsyms_lookup_name("__close_fd_ptr");
+	return __close_fd_ptr(files, fd);
+}
+
+int can_nice(const struct task_struct *p, const int nice)
+{
+	if (!can_nice_ptr)
+		can_nice_ptr = kallsyms_lookup_name("can_nice");
+	return can_nice_ptr(p, nice);
+}
+
+int security_binder_set_context_mgr(struct task_struct *mgr)
+{
+	if (!security_binder_set_context_mgr_ptr)
+		security_binder_set_context_mgr_ptr = kallsyms_lookup_name("security_binder_set_context_mgr");
+	return security_binder_set_context_mgr_ptr(mgr);
+}
+
+int security_binder_transaction(struct task_struct *from, struct task_struct *to)
+{
+	if (!security_binder_transaction_ptr)
+		security_binder_transaction_ptr = kallsyms_lookup_name("security_binder_transaction");
+	return security_binder_transaction_ptr(from, to);
+}
+
+int security_binder_transfer_binder(struct task_struct *from, struct task_struct *to)
+{
+	if (!security_binder_transfer_binder_ptr)
+		security_binder_transfer_binder_ptr = kallsyms_lookup_name("security_binder_transfer_binder");
+	return security_binder_transfer_binder_ptr(from, to);
+}
+
+int security_binder_transfer_file(struct task_struct *from, struct task_struct *to, struct file *file)
+{
+	if (!security_binder_transfer_file_ptr)
+		security_binder_transfer_file_ptr = kallsyms_lookup_name("security_binder_transfer_file");
+	return security_binder_transfer_file_ptr(from, to, file);
+}
diff -Nur a/binder/Makefile b/binder/Makefile
--- a/binder/Makefile	2020-10-31 16:29:01.046635602 +0800
+++ b/binder/Makefile	2020-10-31 16:30:48.642907129 +0800
@@ -1,5 +1,15 @@
-ccflags-y += -I$(src)			# needed for trace events
+ccflags-y += -I$(src) -Wno-int-conversion -DCONFIG_ANDROID_BINDER_DEVICES="\"binder\""
+obj-m := aosp9_binder_linux.o
 
-obj-$(CONFIG_ANDROID_BINDERFS)		+= binderfs.o
-obj-$(CONFIG_ANDROID_BINDER_IPC)	+= binder.o binder_alloc.o
-obj-$(CONFIG_ANDROID_BINDER_IPC_SELFTEST) += binder_alloc_selftest.o
+aosp9_binder_linux-y := deps.o binder_alloc.o binder.o
+
+KERNEL_SRC ?= /lib/modules/$(shell uname -r)/build
+
+all:
+	$(MAKE) -C $(KERNEL_SRC) V=0 M=$$PWD
+
+install:
+	cp  aosp9_binder_linux.ko $(DESTDIR)
+
+clean:
+	rm -rf deps.h *.o *.ko *.mod.c *.symvers *.order .*.cmd .tmp_versions
diff -Nur a/binder/uapi/binder.h b/binder/uapi/binder.h
--- a/binder/uapi/binder.h	2020-10-31 16:29:01.046635602 +0800
+++ b/binder/uapi/binder.h	2020-10-31 16:30:12.202815092 +0800
@@ -41,14 +41,6 @@
 enum {
 	FLAT_BINDER_FLAG_PRIORITY_MASK = 0xff,
 	FLAT_BINDER_FLAG_ACCEPTS_FDS = 0x100,
-
-	/**
-	 * @FLAT_BINDER_FLAG_TXN_SECURITY_CTX: request security contexts
-	 *
-	 * Only when set, causes senders to include their security
-	 * context
-	 */
-	FLAT_BINDER_FLAG_TXN_SECURITY_CTX = 0x1000,
 };
 
 #ifdef BINDER_IPC_32BIT
@@ -226,7 +218,6 @@
 #define BINDER_VERSION			_IOWR('b', 9, struct binder_version)
 #define BINDER_GET_NODE_DEBUG_INFO	_IOWR('b', 11, struct binder_node_debug_info)
 #define BINDER_GET_NODE_INFO_FOR_REF	_IOWR('b', 12, struct binder_node_info_for_ref)
-#define BINDER_SET_CONTEXT_MGR_EXT	_IOW('b', 13, struct flat_binder_object)
 
 /*
  * NOTE: Two special error codes you should check for when calling
@@ -285,11 +276,6 @@
 	} data;
 };
 
-struct binder_transaction_data_secctx {
-	struct binder_transaction_data transaction_data;
-	binder_uintptr_t secctx;
-};
-
 struct binder_transaction_data_sg {
 	struct binder_transaction_data transaction_data;
 	binder_size_t buffers_size;
@@ -325,11 +311,6 @@
 	BR_OK = _IO('r', 1),
 	/* No parameters! */
 
-	BR_TRANSACTION_SEC_CTX = _IOR('r', 2,
-				      struct binder_transaction_data_secctx),
-	/*
-	 * binder_transaction_data_secctx: the received command.
-	 */
 	BR_TRANSACTION = _IOR('r', 2, struct binder_transaction_data),
 	BR_REPLY = _IOR('r', 3, struct binder_transaction_data),
 	/*
