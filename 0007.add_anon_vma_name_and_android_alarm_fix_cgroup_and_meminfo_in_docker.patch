diff -uprN a/Documentation/filesystems/proc.rst b/Documentation/filesystems/proc.rst
--- a/Documentation/filesystems/proc.rst	1987-01-06 02:50:02.924000000 +0800
+++ b/Documentation/filesystems/proc.rst	1987-01-06 02:53:53.704000000 +0800
@@ -431,6 +431,8 @@ is not associated with a file:
  [stack]                    the stack of the main process
  [vdso]                     the "virtual dynamic shared object",
                             the kernel system call handler
+ [anon:<name>]              an anonymous mapping that has been
+                            named by userspace
  =======                    ====================================
 
  or if empty, the mapping is anonymous.
diff -uprN a/drivers/android/alarm/alarm.c b/drivers/android/alarm/alarm.c
--- a/drivers/android/alarm/alarm.c	1970-01-01 08:00:00.000000000 +0800
+++ b/drivers/android/alarm/alarm.c	1987-01-06 02:53:53.720000000 +0800
@@ -0,0 +1,559 @@
+#include <linux/time.h>
+#include <linux/module.h>
+#include <linux/device.h>
+#include <linux/miscdevice.h>
+#include <linux/fs.h>
+#include <linux/platform_device.h>
+#include <linux/sched.h>
+#include <linux/spinlock.h>
+#include <linux/uaccess.h>
+#include <linux/alarmtimer.h>
+#include <linux/vmalloc.h>
+#include <linux/slab.h>
+#include <linux/cdev.h>
+#include <linux/rtc.h>
+#include <linux/timekeeping.h>
+#include "android_alarm.h"
+
+
+#define ANDROID_ALARM_PRINT_INFO (1U << 0)
+#define ANDROID_ALARM_PRINT_IO (1U << 1)
+#define ANDROID_ALARM_PRINT_INT (1U << 2)
+
+#define ALARM_DKMS_MAJOR 508
+#define ALARM_DKMS_MAX_MINOR 256
+
+static DEFINE_MUTEX(alarm_devices_mtx);
+static HLIST_HEAD(alarm_devices);
+
+static int debug_mask = ANDROID_ALARM_PRINT_INFO;
+module_param_named(debug_mask, debug_mask, int, S_IRUGO | S_IWUSR | S_IWGRP);
+
+#define alarm_dbg(debug_level_mask, fmt, ...)				\
+do {									\
+	if (debug_mask & ANDROID_ALARM_PRINT_##debug_level_mask)	\
+		pr_info(fmt, ##__VA_ARGS__);				\
+} while (0)
+
+struct devalarm {
+	union {
+		struct hrtimer hrt;
+		struct alarm alrm;
+	} u;
+	enum android_alarm_type type;
+	struct alarm_context* context;
+};
+
+static int alarm_devices_param = 1;
+module_param_named(num_devices, alarm_devices_param, int, 0444);
+static struct class *alarm_class;
+
+struct alarm_context {
+	const char *name;
+
+	int alarm_opened;
+	spinlock_t alarm_slock;
+	struct wakeup_source* alarm_wake_lock;
+	wait_queue_head_t alarm_wait_queue; 
+	uint32_t alarm_pending;
+	uint32_t alarm_enabled;
+	uint32_t wait_pending;
+
+	struct devalarm alarms[ANDROID_ALARM_TYPE_COUNT];
+};
+
+struct alarm_device {
+	struct hlist_node hlist;
+	struct cdev cdev;
+	struct device class_dev;
+	struct alarm_context context;
+};
+
+static int is_wakeup(enum android_alarm_type type)
+{
+	return (type == ANDROID_ALARM_RTC_WAKEUP ||
+		type == ANDROID_ALARM_ELAPSED_REALTIME_WAKEUP);
+}
+
+static int devalarm_try_to_cancel(struct devalarm *alrm)
+{
+	if (is_wakeup(alrm->type))
+		return alarm_try_to_cancel(&alrm->u.alrm);
+	return hrtimer_try_to_cancel(&alrm->u.hrt);
+}
+
+
+static void alarm_clear(struct alarm_context* context, enum android_alarm_type alarm_type)
+{
+	uint32_t alarm_type_mask = 1U << alarm_type;
+	unsigned long flags;
+
+	spin_lock_irqsave(&context->alarm_slock, flags);
+	alarm_dbg(IO, "alarm %d clear\n", alarm_type);
+	devalarm_try_to_cancel(&context->alarms[alarm_type]);
+	if (context->alarm_pending) {
+		context->alarm_pending &= ~alarm_type_mask;
+		if (!context->alarm_pending && !context->wait_pending)
+			__pm_relax(context->alarm_wake_lock);
+	}
+	context->alarm_enabled &= ~alarm_type_mask;
+	spin_unlock_irqrestore(&context->alarm_slock, flags);
+
+}
+
+static void devalarm_start(struct devalarm *alrm, ktime_t exp)
+{
+	if (is_wakeup(alrm->type))
+		alarm_start(&alrm->u.alrm, exp);
+	else
+		hrtimer_start(&alrm->u.hrt, exp, HRTIMER_MODE_ABS);
+}
+
+static void alarm_set(struct alarm_context* context, enum android_alarm_type alarm_type,
+							struct timespec *ts)
+{
+	uint32_t alarm_type_mask = 1U << alarm_type;
+	unsigned long flags;
+
+	spin_lock_irqsave(&context->alarm_slock, flags);
+	alarm_dbg(IO, "alarm %d set %ld.%09ld\n",
+			alarm_type, ts->tv_sec, ts->tv_nsec);
+	context->alarm_enabled |= alarm_type_mask;
+	devalarm_start(&context->alarms[alarm_type], timespec_to_ktime(*ts));
+	spin_unlock_irqrestore(&context->alarm_slock, flags);
+}
+
+static int alarm_wait(struct alarm_context* context)
+{
+	unsigned long flags;
+	int rv = 0;
+
+	spin_lock_irqsave(&context->alarm_slock, flags);
+	alarm_dbg(IO, "alarm wait\n");
+	if (!context->alarm_pending && context->wait_pending) {
+		__pm_relax(context->alarm_wake_lock);
+		context->wait_pending = 0;
+	}
+	spin_unlock_irqrestore(&context->alarm_slock, flags);
+
+	rv = wait_event_interruptible(context->alarm_wait_queue, context->alarm_pending);
+	if (rv)
+		return rv;
+
+	spin_lock_irqsave(&context->alarm_slock, flags);
+	rv = context->alarm_pending;
+	context->wait_pending = 1;
+	context->alarm_pending = 0;
+	spin_unlock_irqrestore(&context->alarm_slock, flags);
+
+	return rv;
+}
+
+static int alarm_set_rtc(struct alarm_context* context, struct timespec *ts)
+{
+	struct rtc_time new_rtc_tm;
+	struct rtc_device *rtc_dev;
+	unsigned long flags;
+	struct timespec64 ts64;
+	int rv = 0;
+
+	rtc_time64_to_tm(ts->tv_sec, &new_rtc_tm);
+	rtc_dev = alarmtimer_get_rtcdev();
+	rv = do_settimeofday64(&ts64);
+	if (rv < 0)
+		return rv;
+	ts->tv_sec = (time_t)ts64.tv_sec;
+	ts->tv_nsec = ts64.tv_nsec;
+	if (rtc_dev)
+		rv = rtc_set_time(rtc_dev, &new_rtc_tm);
+
+	spin_lock_irqsave(&context->alarm_slock, flags);
+	context->alarm_pending |= ANDROID_ALARM_TIME_CHANGE_MASK;
+	wake_up(&context->alarm_wait_queue);
+	spin_unlock_irqrestore(&context->alarm_slock, flags);
+
+	return rv;
+}
+
+static int alarm_get_time(enum android_alarm_type alarm_type,
+							struct timespec *ts)
+{
+	int rv = 0;
+
+	switch (alarm_type) {
+	case ANDROID_ALARM_RTC_WAKEUP:
+	case ANDROID_ALARM_RTC:
+		getnstimeofday(ts);
+		break;
+	case ANDROID_ALARM_ELAPSED_REALTIME_WAKEUP:
+	case ANDROID_ALARM_ELAPSED_REALTIME:
+		{
+			struct timespec64 ts64;
+			ktime_get_boottime_ts64(&ts64);
+			ts->tv_sec = (time_t)ts64.tv_sec;
+			ts->tv_nsec = ts64.tv_nsec;
+		}
+		break;
+	case ANDROID_ALARM_SYSTEMTIME:
+		ktime_get_ts(ts);
+		break;
+	default:
+		rv = -EINVAL;
+	}
+	return rv;
+}
+
+static long alarm_do_ioctl(struct file *file, unsigned int cmd,
+							struct timespec *ts)
+{
+	int rv = 0;
+	struct alarm_device* alarm_dev = NULL;
+	struct alarm_context* context = NULL;
+	alarm_dev = file->private_data; 
+	context = &alarm_dev->context;
+
+	enum android_alarm_type alarm_type = ANDROID_ALARM_IOCTL_TO_TYPE(cmd);
+
+	if (alarm_type >= ANDROID_ALARM_TYPE_COUNT)
+		return -EINVAL;
+
+	if(alarm_dev == NULL){
+		return -EBUSY;
+	}
+
+	if (ANDROID_ALARM_BASE_CMD(cmd) != ANDROID_ALARM_GET_TIME(0)) {
+		if ((file->f_flags & O_ACCMODE) == O_RDONLY)
+			return -EPERM;
+	}
+
+	switch (ANDROID_ALARM_BASE_CMD(cmd)) {
+	case ANDROID_ALARM_CLEAR(0):
+		alarm_clear(context, alarm_type);
+		break;
+	case ANDROID_ALARM_SET(0):
+		alarm_set(context, alarm_type, ts);
+		break;
+	case ANDROID_ALARM_SET_AND_WAIT(0):
+		alarm_set(context, alarm_type, ts);
+		/* fall though */
+	case ANDROID_ALARM_WAIT:
+		rv = alarm_wait(context);
+		break;
+	case ANDROID_ALARM_SET_RTC:
+		rv = alarm_set_rtc(context, ts);
+		break;
+	case ANDROID_ALARM_GET_TIME(0):
+		rv = alarm_get_time(alarm_type, ts);
+		break;
+
+	default:
+		rv = -EINVAL;
+	}
+	return rv;
+}
+
+static long alarm_ioctl(struct file *file, unsigned int cmd, unsigned long arg)
+{
+	struct timespec ts;
+	int rv;
+
+	switch (ANDROID_ALARM_BASE_CMD(cmd)) {
+	case ANDROID_ALARM_SET_AND_WAIT(0):
+	case ANDROID_ALARM_SET(0):
+	case ANDROID_ALARM_SET_RTC:
+		if (copy_from_user(&ts, (void __user *)arg, sizeof(ts)))
+			return -EFAULT;
+		break;
+	}
+
+	rv = alarm_do_ioctl(file, cmd, &ts);
+	if (rv)
+		return rv;
+
+	switch (ANDROID_ALARM_BASE_CMD(cmd)) {
+	case ANDROID_ALARM_GET_TIME(0):
+		if (copy_to_user((void __user *)arg, &ts, sizeof(ts)))
+			return -EFAULT;
+		break;
+	}
+
+	return 0;
+}
+
+static int alarm_open(struct inode *inode, struct file *file)
+{
+	int minor = iminor(inode);
+	struct hlist_node *tmp;
+    struct alarm_device *alarm_dev;
+	file->private_data = NULL;
+	
+	printk("alarm_open minor: %d\n", minor);
+
+	mutex_lock(&alarm_devices_mtx);
+	hlist_for_each_entry_safe(alarm_dev, tmp, &alarm_devices, hlist) {
+		if (MINOR(alarm_dev->cdev.dev) == minor)
+			break;
+		alarm_dev = NULL;
+	}
+	mutex_unlock(&alarm_devices_mtx);
+
+	file->private_data = alarm_dev;
+
+	return 0;
+}
+
+static void devalarm_cancel(struct devalarm *alrm)
+{
+	if (is_wakeup(alrm->type))
+		alarm_cancel(&alrm->u.alrm);
+	else
+		hrtimer_cancel(&alrm->u.hrt);
+}
+
+static int alarm_release(struct inode *inode, struct file *file)
+{
+	int i;
+	unsigned long flags;
+	struct alarm_device* alarm_dev = NULL;
+	struct alarm_context* context = NULL;
+	alarm_dev = file->private_data; 
+
+	if (alarm_dev) {
+		context = &alarm_dev->context;
+		spin_lock_irqsave(&context->alarm_slock, flags);
+		for (i = 0; i < ANDROID_ALARM_TYPE_COUNT; i++) {
+			uint32_t alarm_type_mask = 1U << i;
+			if (context->alarm_enabled & alarm_type_mask) {
+				alarm_dbg(INFO,
+					"%s: clear alarm, pending %d\n",
+					__func__,
+					!!(context->alarm_pending & alarm_type_mask));
+				context->alarm_enabled &= ~alarm_type_mask;
+			}
+			spin_unlock_irqrestore(&context->alarm_slock, flags);
+			devalarm_cancel(&context->alarms[i]);
+			spin_lock_irqsave(&context->alarm_slock, flags);
+		}
+		if (context->alarm_pending | context->wait_pending) {
+			if (context->alarm_pending)
+				alarm_dbg(INFO, "%s: clear pending alarms %x\n",
+					__func__, context->alarm_pending);
+			__pm_relax(context->alarm_wake_lock);
+			context->wait_pending = 0;
+			context->alarm_pending = 0;
+		}
+		context->alarm_opened = 0;
+		spin_unlock_irqrestore(&context->alarm_slock, flags);
+	}
+	return 0;
+}
+
+static const struct file_operations alarm_fops = {
+	.owner = THIS_MODULE,
+	.unlocked_ioctl = alarm_ioctl,
+	.open = alarm_open,
+	.release = alarm_release,
+};
+
+static void alarm_device_release(struct device *dev)
+{
+}
+
+static void devalarm_triggered(struct devalarm *alarm)
+{
+	unsigned long flags;
+	uint32_t alarm_type_mask = 1U << alarm->type;
+	struct alarm_context* context = alarm->context;
+
+	alarm_dbg(INT, "%s: type %d\n", __func__, alarm->type);
+	spin_lock_irqsave(&context->alarm_slock, flags);
+	if (context->alarm_enabled & alarm_type_mask) {
+		__pm_wakeup_event(context->alarm_wake_lock, 5000); /* 5secs */
+		context->alarm_enabled &= ~alarm_type_mask;
+		context->alarm_pending |= alarm_type_mask;
+		wake_up(&context->alarm_wait_queue);
+	}
+	spin_unlock_irqrestore(&context->alarm_slock, flags);
+}
+
+static enum hrtimer_restart devalarm_hrthandler(struct hrtimer *hrt)
+{
+	struct devalarm *devalrm = container_of(hrt, struct devalarm, u.hrt);
+
+	devalarm_triggered(devalrm);
+	return HRTIMER_NORESTART;
+}
+
+static enum alarmtimer_restart devalarm_alarmhandler(struct alarm *alrm,
+							ktime_t now)
+{
+	struct devalarm *devalrm = container_of(alrm, struct devalarm, u.alrm);
+
+	devalarm_triggered(devalrm);
+	return ALARMTIMER_NORESTART;
+}
+
+static int __init init_alarm_device(int idx)
+{
+    int ret;
+	int i;
+	char *name;
+	dev_t devnr;
+	struct alarm_device *alarm_device;
+	/* strlen("binder")
+	 * +
+	 * maximum length of 64 bit int as string
+	 */
+	char numstr[6 + 21] = "alarm";
+
+	alarm_device = kzalloc(sizeof(*alarm_device), GFP_KERNEL);
+	if (!alarm_device)
+		return -ENOMEM;
+
+	cdev_init(&alarm_device->cdev, &alarm_fops);
+	alarm_device->cdev.owner = THIS_MODULE;
+
+	devnr = MKDEV(ALARM_DKMS_MAJOR, idx);
+	ret = cdev_add(&alarm_device->cdev, devnr, 1);
+	if (ret) {
+		kfree(alarm_device);
+		return ret;
+	}
+
+	if (alarm_devices_param > 1)
+		ret = snprintf(numstr, sizeof(numstr), "alarm%d", idx);
+	if (ret < 0 || (size_t)ret >= sizeof(numstr)) {
+		cdev_del(&alarm_device->cdev);
+		kfree(alarm_device);
+		return -EIO;
+	}
+
+	name = kzalloc(strlen(numstr) + 1, GFP_KERNEL);
+	if (!name) {
+		cdev_del(&alarm_device->cdev);
+		kfree(alarm_device);
+		return -ENOMEM;
+	}
+	strcpy(name, numstr);
+	alarm_device->context.name = name;
+	alarm_device->context.alarm_slock = __SPIN_LOCK_UNLOCKED(alarm_slock);
+	init_waitqueue_head(&alarm_device->context.alarm_wait_queue);
+
+	alarm_device->class_dev.devt = alarm_device->cdev.dev;
+	alarm_device->class_dev.class = alarm_class;
+	alarm_device->class_dev.release = alarm_device_release;
+	dev_set_name(&alarm_device->class_dev, "%s", name);
+	ret = device_register(&alarm_device->class_dev);
+	if (ret) {
+		cdev_del(&alarm_device->cdev);
+		kfree(alarm_device);
+		kfree(name);
+		return ret;
+	}
+
+	for (i = 0; i < ANDROID_ALARM_TYPE_COUNT; i++) {
+		alarm_device->context.alarms[i].context = &alarm_device->context;
+	}
+
+	alarm_init(&alarm_device->context.alarms[ANDROID_ALARM_RTC_WAKEUP].u.alrm,
+			ALARM_REALTIME, devalarm_alarmhandler);
+	hrtimer_init(&alarm_device->context.alarms[ANDROID_ALARM_RTC].u.hrt,
+			CLOCK_REALTIME, HRTIMER_MODE_ABS);
+	alarm_init(&alarm_device->context.alarms[ANDROID_ALARM_ELAPSED_REALTIME_WAKEUP].u.alrm,
+			ALARM_BOOTTIME, devalarm_alarmhandler);
+	hrtimer_init(&alarm_device->context.alarms[ANDROID_ALARM_ELAPSED_REALTIME].u.hrt,
+			CLOCK_BOOTTIME, HRTIMER_MODE_ABS);
+	hrtimer_init(&alarm_device->context.alarms[ANDROID_ALARM_SYSTEMTIME].u.hrt,
+			CLOCK_MONOTONIC, HRTIMER_MODE_ABS);
+
+	for (i = 0; i < ANDROID_ALARM_TYPE_COUNT; i++) {
+		alarm_device->context.alarms[i].type = i;
+		if (!is_wakeup(i))
+			alarm_device->context.alarms[i].u.hrt.function = devalarm_hrthandler;
+	}
+
+	alarm_device->context.alarm_wake_lock = wakeup_source_create(name);
+	wakeup_source_add(alarm_device->context.alarm_wake_lock);
+
+	mutex_lock(&alarm_devices_mtx);
+	hlist_add_head(&alarm_device->hlist, &alarm_devices);
+	mutex_unlock(&alarm_devices_mtx);
+
+	return 0;
+}
+
+static int __init alarm_dev_init(void)
+{
+    int i, ret;
+    struct alarm_device *device;
+    struct hlist_node *tmp;
+    
+    ret = register_chrdev_region(MKDEV(ALARM_DKMS_MAJOR, 0), ALARM_DKMS_MAX_MINOR, "alarm");
+    if (ret){
+        printk("register_chrdev_region %d\n", ret);
+        return ret;
+    }    
+    
+    alarm_class = class_create(THIS_MODULE, "alarm");
+	if (IS_ERR(alarm_class))
+		goto on_error_unregister_chrdev_region;
+
+	for (i = 1; i <= alarm_devices_param; i++) {
+		ret = init_alarm_device(i);
+		if (ret)
+			goto err_init_device_failed;
+	}
+
+	return ret;
+    
+err_init_device_failed:
+	mutex_lock(&alarm_devices_mtx);
+	hlist_for_each_entry_safe(device, tmp, &alarm_devices, hlist) {
+		cdev_del(&device->cdev);
+		device_unregister(&device->class_dev);
+		kfree(device->context.name);
+		hlist_del(&device->hlist);
+		kfree(device);
+	}
+	mutex_unlock(&alarm_devices_mtx);
+	class_destroy(alarm_class);
+    
+on_error_unregister_chrdev_region:
+   unregister_chrdev_region(MKDEV(ALARM_DKMS_MAJOR, 0),
+				 ALARM_DKMS_MAX_MINOR);
+
+                 
+    return -1;
+}
+
+
+
+static void  __exit alarm_dev_exit(void)
+{
+    struct alarm_device *device;
+	struct hlist_node *tmp;
+
+	mutex_lock(&alarm_devices_mtx);
+	hlist_for_each_entry_safe(device, tmp, &alarm_devices, hlist) {
+		wakeup_source_remove(device->context.alarm_wake_lock);
+		wakeup_source_destroy(device->context.alarm_wake_lock);
+		cdev_del(&device->cdev);
+		device_unregister(&device->class_dev);
+		kfree(device->context.name);
+		hlist_del(&device->hlist);
+		kfree(device);
+	}
+	mutex_unlock(&alarm_devices_mtx);
+
+	class_destroy(alarm_class);
+
+	unregister_chrdev_region(MKDEV(ALARM_DKMS_MAJOR, 0),
+				 ALARM_DKMS_MAX_MINOR);
+}
+
+
+
+module_init(alarm_dev_init);
+module_exit(alarm_dev_exit);
+
+MODULE_LICENSE("GPL v2");
diff -uprN a/drivers/android/alarm/android_alarm.h b/drivers/android/alarm/android_alarm.h
--- a/drivers/android/alarm/android_alarm.h	1970-01-01 08:00:00.000000000 +0800
+++ b/drivers/android/alarm/android_alarm.h	1987-01-06 02:53:53.720000000 +0800
@@ -0,0 +1,126 @@
+/* include/linux/android_alarm.h
+ *
+ * Copyright (C) 2006-2007 Google, Inc.
+ *
+ * This software is licensed under the terms of the GNU General Public
+ * License version 2, as published by the Free Software Foundation, and
+ * may be copied, distributed, and modified under those terms.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ */
+
+#ifndef _LINUX_ANDROID_ALARM_H
+#define _LINUX_ANDROID_ALARM_H
+
+#include <linux/compat.h>
+#include <linux/ioctl.h>
+
+#ifndef _STRUCT_TIMESPEC
+#define _STRUCT_TIMESPEC
+struct timespec {
+        __kernel_old_time_t     tv_sec;         /* seconds */
+        long                    tv_nsec;        /* nanoseconds */
+};
+#endif
+
+#ifndef _TIME_T
+#define _TIME_T
+typedef __kernel_long_t __kernel_time_t;
+typedef __kernel_time_t         time_t;
+#endif
+
+#if __BITS_PER_LONG == 64
+
+/* timespec64 is defined as timespec here */
+static inline struct timespec timespec64_to_timespec(const struct timespec64 ts64)
+{
+        return *(const struct timespec *)&ts64;
+}
+
+static inline struct timespec64 timespec_to_timespec64(const struct timespec ts)
+{
+        return *(const struct timespec64 *)&ts;
+}
+
+#else
+static inline struct timespec timespec64_to_timespec(const struct timespec64 ts64)
+{
+        struct timespec ret;
+
+        ret.tv_sec = (time_t)ts64.tv_sec;
+        ret.tv_nsec = ts64.tv_nsec;
+        return ret;
+}
+
+static inline struct timespec64 timespec_to_timespec64(const struct timespec ts)
+{
+        struct timespec64 ret;
+
+        ret.tv_sec = ts.tv_sec;
+        ret.tv_nsec = ts.tv_nsec;
+        return ret;
+}
+#endif
+
+
+static inline void getnstimeofday(struct timespec *ts)
+{
+        struct timespec64 ts64;
+
+        ktime_get_real_ts64(&ts64);
+        *ts = timespec64_to_timespec(ts64);
+}
+
+static inline void ktime_get_ts(struct timespec *ts)
+{
+        struct timespec64 ts64;
+
+        ktime_get_ts64(&ts64);
+        *ts = timespec64_to_timespec(ts64);
+}
+
+static inline void getrawmonotonic(struct timespec *ts)
+{
+        struct timespec64 ts64;
+
+        ktime_get_raw_ts64(&ts64);
+        *ts = timespec64_to_timespec(ts64);
+}
+
+static inline void getboottime(struct timespec *ts)
+{
+        struct timespec64 ts64;
+
+        getboottime64(&ts64);
+        *ts = timespec64_to_timespec(ts64);
+}
+
+static inline ktime_t timespec_to_ktime(struct timespec ts)
+{
+        return ktime_set(ts.tv_sec, ts.tv_nsec);
+}
+
+#include "uapi/android_alarm.h"
+
+#ifdef CONFIG_COMPAT
+#define ANDROID_ALARM_SET_COMPAT(type)		ALARM_IOW(2, type, \
+							struct compat_timespec)
+#define ANDROID_ALARM_SET_AND_WAIT_COMPAT(type)	ALARM_IOW(3, type, \
+							struct compat_timespec)
+#define ANDROID_ALARM_GET_TIME_COMPAT(type)	ALARM_IOW(4, type, \
+							struct compat_timespec)
+#define ANDROID_ALARM_SET_RTC_COMPAT		_IOW('a', 5, \
+							struct compat_timespec)
+#define ANDROID_ALARM_IOCTL_NR(cmd)		(_IOC_NR(cmd) & ((1<<4)-1))
+#define ANDROID_ALARM_COMPAT_TO_NORM(cmd)  \
+				ALARM_IOW(ANDROID_ALARM_IOCTL_NR(cmd), \
+					ANDROID_ALARM_IOCTL_TO_TYPE(cmd), \
+					struct timespec)
+
+#endif
+
+#endif
diff -uprN a/drivers/android/alarm/deps.c b/drivers/android/alarm/deps.c
--- a/drivers/android/alarm/deps.c	1970-01-01 08:00:00.000000000 +0800
+++ b/drivers/android/alarm/deps.c	1987-01-06 02:53:53.720000000 +0800
@@ -0,0 +1,181 @@
+#include <linux/mm.h>
+#include <linux/rtc.h>
+#include <linux/kallsyms.h>
+
+int (*alarm_cancel_ptr)(struct alarm *alarm) = NULL;
+int alarm_cancel(struct alarm *alarm)
+{
+    if (!alarm_cancel_ptr)
+		alarm_cancel_ptr = kallsyms_lookup_name("alarm_cancel");
+	return alarm_cancel_ptr(alarm);
+    
+}
+
+struct rtc_device* (*alarmtimer_get_rtcdev_ptr)(void) = NULL;
+struct rtc_device *alarmtimer_get_rtcdev(void)
+{
+    if (!alarmtimer_get_rtcdev_ptr)
+		alarmtimer_get_rtcdev_ptr = kallsyms_lookup_name("alarmtimer_get_rtcdev");
+	return alarmtimer_get_rtcdev_ptr();
+}
+
+
+void (*alarm_init_ptr)(struct alarm *alarm, enum alarmtimer_type type,
+		enum alarmtimer_restart (*function)(struct alarm *, ktime_t)) = NULL;
+
+void alarm_init(struct alarm *alarm, enum alarmtimer_type type,
+		enum alarmtimer_restart (*function)(struct alarm *, ktime_t))
+{
+    if(!alarm_init_ptr)
+        alarm_init_ptr = kallsyms_lookup_name("alarm_init");
+    alarm_init_ptr(alarm, type, function);
+}
+
+
+void (*alarm_start_ptr)(struct alarm *alarm, ktime_t start) = NULL;
+void alarm_start(struct alarm *alarm, ktime_t start)
+{
+    if(!alarm_start_ptr)
+        alarm_start_ptr = kallsyms_lookup_name("alarm_start");
+    alarm_start_ptr(alarm, start);
+}
+
+
+int (*alarm_try_to_cancel_ptr)(struct alarm *alarm) = NULL;
+int alarm_try_to_cancel(struct alarm *alarm)
+{
+    if(!alarm_try_to_cancel_ptr)
+        alarm_try_to_cancel_ptr = kallsyms_lookup_name("alarm_try_to_cancel");
+    return alarm_try_to_cancel_ptr(alarm);
+}
+
+
+void (*wakeup_source_remove_ptr)(struct wakeup_source *ws) = NULL;
+void wakeup_source_remove(struct wakeup_source *ws)
+{
+    if(!wakeup_source_remove_ptr)
+        wakeup_source_remove_ptr = kallsyms_lookup_name("wakeup_source_remove");
+    wakeup_source_remove_ptr(ws);   
+}
+
+void (*wakeup_source_drop_ptr)(struct wakeup_source *ws) = NULL;
+void wakeup_source_drop(struct wakeup_source *ws)
+{
+    if(!wakeup_source_drop_ptr)
+        wakeup_source_drop_ptr = kallsyms_lookup_name("wakeup_source_drop");
+    wakeup_source_drop_ptr(ws);   
+}
+
+
+void (*ktime_get_ts64_ptr)(struct timespec64 *ts) = NULL;
+void ktime_get_ts64(struct timespec64 *ts)
+{
+    if(!ktime_get_ts64_ptr)
+        ktime_get_ts64_ptr = kallsyms_lookup_name("ktime_get_ts64");
+    ktime_get_ts64_ptr(ts);  
+}
+
+int (*hrtimer_try_to_cancel_ptr)(struct hrtimer *timer) = NULL;
+int hrtimer_try_to_cancel(struct hrtimer *timer)
+{
+    if(!hrtimer_try_to_cancel_ptr)
+        hrtimer_try_to_cancel_ptr = kallsyms_lookup_name("hrtimer_try_to_cancel");
+    return hrtimer_try_to_cancel_ptr(timer);
+    
+}
+
+void (*hrtimer_init_ptr)(struct hrtimer *timer, clockid_t clock_id, enum hrtimer_mode mode) = NULL;
+void hrtimer_init(struct hrtimer *timer, clockid_t clock_id, enum hrtimer_mode mode)
+{
+   if(!hrtimer_init_ptr)
+        hrtimer_init_ptr = kallsyms_lookup_name("hrtimer_init");
+     hrtimer_init_ptr(timer, clock_id, mode);
+}
+
+void (*hrtimer_start_range_ns_ptr)(struct hrtimer *timer, ktime_t tim, u64 range_ns, const enum hrtimer_mode mode) = NULL;
+void hrtimer_start_range_ns(struct hrtimer *timer, ktime_t tim, u64 range_ns, const enum hrtimer_mode mode)
+{
+     if(!hrtimer_start_range_ns_ptr)
+        hrtimer_start_range_ns_ptr = kallsyms_lookup_name("hrtimer_start_range_ns");
+     hrtimer_start_range_ns_ptr(timer, tim, range_ns, mode);
+}
+
+void (*wakeup_source_prepare_ptr)(struct wakeup_source *ws, const char *name) = NULL;
+void wakeup_source_prepare(struct wakeup_source *ws, const char *name)
+{
+    if(!wakeup_source_prepare_ptr)
+        wakeup_source_prepare_ptr = kallsyms_lookup_name("wakeup_source_prepare");
+     wakeup_source_prepare_ptr(ws, name);
+    
+}
+
+
+void  (*wakeup_source_add_ptr)(struct wakeup_source *ws) = NULL;
+void wakeup_source_add(struct wakeup_source *ws)
+{
+     if(!wakeup_source_add_ptr)
+        wakeup_source_add_ptr = kallsyms_lookup_name("wakeup_source_add");
+     wakeup_source_add_ptr(ws);
+    
+}
+
+int (*hrtimer_cancel_ptr)(struct hrtimer *timer) = NULL;
+int hrtimer_cancel(struct hrtimer *timer)
+{
+     if(!hrtimer_cancel_ptr)
+        hrtimer_cancel_ptr = kallsyms_lookup_name("hrtimer_cancel");
+     return hrtimer_cancel_ptr(timer);
+}
+
+int (*compat_put_timespec_ptr)(const struct timespec *ts, void __user *uts) = NULL;
+int compat_put_timespec(const struct timespec *ts, void __user *uts)
+{
+    if(!compat_put_timespec_ptr)
+        compat_put_timespec_ptr = kallsyms_lookup_name("compat_put_timespec");
+     return compat_put_timespec_ptr(ts, uts);
+    
+}
+
+int (*compat_get_timespec_ptr)(struct timespec *ts, const void __user *uts) = NULL;
+int compat_get_timespec(struct timespec *ts, const void __user *uts)
+{
+     if(!compat_get_timespec_ptr)
+        compat_get_timespec_ptr = kallsyms_lookup_name("compat_get_timespec");
+     return compat_get_timespec_ptr(ts, uts);
+}
+
+
+int (*rtc_set_time_ptr)(struct rtc_device *rtc, struct rtc_time *tm) = NULL;
+int rtc_set_time(struct rtc_device *rtc, struct rtc_time *tm)
+{
+     if(!rtc_set_time_ptr)
+        rtc_set_time_ptr = kallsyms_lookup_name("rtc_set_time");
+     return rtc_set_time_ptr(rtc, tm);
+}
+
+ktime_t (*ktime_get_with_offset_ptr)(enum tk_offsets offs);
+ktime_t ktime_get_with_offset(enum tk_offsets offs)
+{
+    if(!ktime_get_with_offset_ptr)
+        ktime_get_with_offset_ptr = kallsyms_lookup_name("ktime_get_with_offset");
+     return ktime_get_with_offset_ptr(offs);
+    
+}
+
+void (*__pm_relax_ptr)(struct wakeup_source *ws) = NULL;
+void __pm_relax(struct wakeup_source *ws)
+{
+     if(!__pm_relax_ptr)
+        __pm_relax_ptr = kallsyms_lookup_name("__pm_relax");
+     __pm_relax_ptr(ws);
+}
+
+void (*pm_wakeup_ws_event_ptr)(struct wakeup_source *ws, unsigned int msec, bool hard) = NULL;
+void pm_wakeup_ws_event(struct wakeup_source *ws, unsigned int msec, bool hard)
+{
+    if(!pm_wakeup_ws_event_ptr)
+        pm_wakeup_ws_event_ptr = kallsyms_lookup_name("pm_wakeup_ws_event");
+     pm_wakeup_ws_event_ptr(ws, msec, hard);
+    
+}
+
diff -uprN a/drivers/android/alarm/dkms.conf b/drivers/android/alarm/dkms.conf
--- a/drivers/android/alarm/dkms.conf	1970-01-01 08:00:00.000000000 +0800
+++ b/drivers/android/alarm/dkms.conf	1987-01-06 02:53:53.720000000 +0800
@@ -0,0 +1,7 @@
+PACKAGE_NAME="anbox-alarm"
+PACKAGE_VERSION="1"
+CLEAN="make clean"
+MAKE[0]="make all KERNEL_SRC=/lib/modules/$kernelver/build"
+BUILT_MODULE_NAME[0]="alarm_linux"
+DEST_MODULE_LOCATION[0]="/updates"
+AUTOINSTALL="yes"
diff -uprN a/drivers/android/alarm/Kconfig b/drivers/android/alarm/Kconfig
--- a/drivers/android/alarm/Kconfig	1970-01-01 08:00:00.000000000 +0800
+++ b/drivers/android/alarm/Kconfig	1987-01-06 02:53:53.720000000 +0800
@@ -0,0 +1,3 @@
+config ANDROID_ALARM
+	tristate "Android Alarm Driver"
+	default m
diff -uprN a/drivers/android/alarm/Makefile b/drivers/android/alarm/Makefile
--- a/drivers/android/alarm/Makefile	1970-01-01 08:00:00.000000000 +0800
+++ b/drivers/android/alarm/Makefile	1987-01-06 02:53:53.720000000 +0800
@@ -0,0 +1,3 @@
+flags-y += -I$(src) -Wno-error=implicit-int -Wno-int-conversion -g3 -O3
+alarm_linux-y := alarm.o
+obj-$(CONFIG_ANDROID_ALARM) += alarm_linux.o
diff -uprN a/drivers/android/alarm/uapi/android_alarm.h b/drivers/android/alarm/uapi/android_alarm.h
--- a/drivers/android/alarm/uapi/android_alarm.h	1970-01-01 08:00:00.000000000 +0800
+++ b/drivers/android/alarm/uapi/android_alarm.h	1987-01-06 02:53:53.720000000 +0800
@@ -0,0 +1,62 @@
+/* drivers/staging/android/uapi/android_alarm.h
+ *
+ * Copyright (C) 2006-2007 Google, Inc.
+ *
+ * This software is licensed under the terms of the GNU General Public
+ * License version 2, as published by the Free Software Foundation, and
+ * may be copied, distributed, and modified under those terms.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ */
+
+#ifndef _UAPI_LINUX_ANDROID_ALARM_H
+#define _UAPI_LINUX_ANDROID_ALARM_H
+
+#include <linux/ioctl.h>
+#include <linux/time.h>
+
+enum android_alarm_type {
+	/* return code bit numbers or set alarm arg */
+	ANDROID_ALARM_RTC_WAKEUP,
+	ANDROID_ALARM_RTC,
+	ANDROID_ALARM_ELAPSED_REALTIME_WAKEUP,
+	ANDROID_ALARM_ELAPSED_REALTIME,
+	ANDROID_ALARM_SYSTEMTIME,
+
+	ANDROID_ALARM_TYPE_COUNT,
+
+	/* return code bit numbers */
+	/* ANDROID_ALARM_TIME_CHANGE = 16 */
+};
+
+enum android_alarm_return_flags {
+	ANDROID_ALARM_RTC_WAKEUP_MASK = 1U << ANDROID_ALARM_RTC_WAKEUP,
+	ANDROID_ALARM_RTC_MASK = 1U << ANDROID_ALARM_RTC,
+	ANDROID_ALARM_ELAPSED_REALTIME_WAKEUP_MASK =
+				1U << ANDROID_ALARM_ELAPSED_REALTIME_WAKEUP,
+	ANDROID_ALARM_ELAPSED_REALTIME_MASK =
+				1U << ANDROID_ALARM_ELAPSED_REALTIME,
+	ANDROID_ALARM_SYSTEMTIME_MASK = 1U << ANDROID_ALARM_SYSTEMTIME,
+	ANDROID_ALARM_TIME_CHANGE_MASK = 1U << 16
+};
+
+/* Disable alarm */
+#define ANDROID_ALARM_CLEAR(type)           _IO('a', 0 | ((type) << 4))
+
+/* Ack last alarm and wait for next */
+#define ANDROID_ALARM_WAIT                  _IO('a', 1)
+
+#define ALARM_IOW(c, type, size)            _IOW('a', (c) | ((type) << 4), size)
+/* Set alarm */
+#define ANDROID_ALARM_SET(type)             ALARM_IOW(2, type, struct timespec)
+#define ANDROID_ALARM_SET_AND_WAIT(type)    ALARM_IOW(3, type, struct timespec)
+#define ANDROID_ALARM_GET_TIME(type)        ALARM_IOW(4, type, struct timespec)
+#define ANDROID_ALARM_SET_RTC               _IOW('a', 5, struct timespec)
+#define ANDROID_ALARM_BASE_CMD(cmd)         (cmd & ~(_IOC(0, 0, 0xf0, 0)))
+#define ANDROID_ALARM_IOCTL_TO_TYPE(cmd)    (_IOC_NR(cmd) >> 4)
+
+#endif
diff -uprN a/drivers/android/Kconfig b/drivers/android/Kconfig
--- a/drivers/android/Kconfig	1987-01-06 02:50:02.924000000 +0800
+++ b/drivers/android/Kconfig	1987-01-06 02:53:53.720000000 +0800
@@ -53,6 +53,7 @@ config ANDROID_BINDER_IPC_SELFTEST
 	  Binder selftest checks the allocation and free of binder buffers
 	  exhaustively with combinations of various buffer sizes and
 	  alignments.
+source "drivers/android/alarm/Kconfig"	  
 
 endif # if ANDROID
 
diff -uprN a/drivers/android/Makefile b/drivers/android/Makefile
--- a/drivers/android/Makefile	1987-01-06 02:50:02.924000000 +0800
+++ b/drivers/android/Makefile	1987-01-06 02:53:53.720000000 +0800
@@ -4,3 +4,4 @@ ccflags-y += -I$(src)			# needed for tra
 obj-$(CONFIG_ANDROID_BINDERFS)		+= binderfs.o
 obj-$(CONFIG_ANDROID_BINDER_IPC)	+= binder.o binder_alloc.o
 obj-$(CONFIG_ANDROID_BINDER_IPC_SELFTEST) += binder_alloc_selftest.o
+obj-$(CONFIG_ANDROID_ALARM) += alarm/
\ No newline at end of file
diff -uprN a/fs/proc/task_mmu.c b/fs/proc/task_mmu.c
--- a/fs/proc/task_mmu.c	1987-01-06 02:50:02.924000000 +0800
+++ b/fs/proc/task_mmu.c	1987-01-06 02:53:53.708000000 +0800
@@ -309,6 +309,8 @@ show_map_vma(struct seq_file *m, struct
 
 	name = arch_vma_name(vma);
 	if (!name) {
+        const char *anon_name;
+
 		if (!mm) {
 			name = "[vdso]";
 			goto done;
@@ -320,8 +322,16 @@ show_map_vma(struct seq_file *m, struct
 			goto done;
 		}
 
-		if (is_stack(vma))
+		if (is_stack(vma)) {
 			name = "[stack]";
+		    goto done;
+		}
+		
+        anon_name = vma_anon_name(vma);
+        if (anon_name) {
+            seq_pad(m, ' ');
+            seq_printf(m, "[anon:%s]", anon_name);
+        }		
 	}
 
 done:
diff -uprN a/fs/userfaultfd.c b/fs/userfaultfd.c
--- a/fs/userfaultfd.c	1987-01-06 02:50:02.924000000 +0800
+++ b/fs/userfaultfd.c	1987-01-06 02:53:53.708000000 +0800
@@ -881,7 +881,7 @@ static int userfaultfd_release(struct in
 				 new_flags, vma->anon_vma,
 				 vma->vm_file, vma->vm_pgoff,
 				 vma_policy(vma),
-				 NULL_VM_UFFD_CTX);
+				 NULL_VM_UFFD_CTX, vma_anon_name(vma));
 		if (prev)
 			vma = prev;
 		else
@@ -1444,7 +1444,8 @@ static int userfaultfd_register(struct u
 		prev = vma_merge(mm, prev, start, vma_end, new_flags,
 				 vma->anon_vma, vma->vm_file, vma->vm_pgoff,
 				 vma_policy(vma),
-				 ((struct vm_userfaultfd_ctx){ ctx }));
+				 ((struct vm_userfaultfd_ctx){ ctx }),
+				 vma_anon_name(vma));
 		if (prev) {
 			vma = prev;
 			goto next;
@@ -1614,7 +1615,7 @@ static int userfaultfd_unregister(struct
 		prev = vma_merge(mm, prev, start, vma_end, new_flags,
 				 vma->anon_vma, vma->vm_file, vma->vm_pgoff,
 				 vma_policy(vma),
-				 NULL_VM_UFFD_CTX);
+				 NULL_VM_UFFD_CTX, vma_anon_name(vma));
 		if (prev) {
 			vma = prev;
 			goto next;
diff -uprN a/include/linux/memcontrol.h b/include/linux/memcontrol.h
--- a/include/linux/memcontrol.h	1987-01-06 02:50:02.924000000 +0800
+++ b/include/linux/memcontrol.h	1987-01-06 02:53:53.708000000 +0800
@@ -1049,6 +1049,8 @@ static inline void mod_memcg_page_state(
 		mod_memcg_state(memcg, idx, val);
 }
 
+unsigned long memcg_page_state(struct mem_cgroup *memcg, int idx);
+
 static inline unsigned long lruvec_page_state(struct lruvec *lruvec,
 					      enum node_stat_item idx)
 {
diff -uprN a/include/linux/mm.h b/include/linux/mm.h
--- a/include/linux/mm.h	1987-01-06 02:50:02.924000000 +0800
+++ b/include/linux/mm.h	1987-01-06 02:53:53.708000000 +0800
@@ -2569,7 +2569,7 @@ static inline int vma_adjust(struct vm_a
 extern struct vm_area_struct *vma_merge(struct mm_struct *,
 	struct vm_area_struct *prev, unsigned long addr, unsigned long end,
 	unsigned long vm_flags, struct anon_vma *, struct file *, pgoff_t,
-	struct mempolicy *, struct vm_userfaultfd_ctx);
+	struct mempolicy *, struct vm_userfaultfd_ctx, const char *);
 extern struct anon_vma *find_mergeable_anon_vma(struct vm_area_struct *);
 extern int __split_vma(struct mm_struct *, struct vm_area_struct *,
 	unsigned long addr, int new_below);
@@ -3264,5 +3264,16 @@ static inline int seal_check_future_writ
 	return 0;
 }
 
+#ifdef CONFIG_ANON_VMA_NAME
+int madvise_set_anon_name(struct mm_struct *mm, unsigned long start,
+                         unsigned long len_in, const char *name);
+#else
+static inline int
+madvise_set_anon_name(struct mm_struct *mm, unsigned long start,
+                     unsigned long len_in, const char *name) {
+       return 0;
+}
+#endif
+
 #endif /* __KERNEL__ */
 #endif /* _LINUX_MM_H */
diff -uprN a/include/linux/mm_types.h b/include/linux/mm_types.h
--- a/include/linux/mm_types.h	1987-01-06 02:50:02.924000000 +0800
+++ b/include/linux/mm_types.h	1987-01-06 02:53:53.708000000 +0800
@@ -340,11 +340,17 @@ struct vm_area_struct {
 	/*
 	 * For areas with an address space and backing store,
 	 * linkage into the address_space->i_mmap interval tree.
+     * For private anonymous mappings, a pointer to a null terminated string
+     * containing the name given to the vma, or NULL if unnamed.
 	 */
-	struct {
-		struct rb_node rb;
-		unsigned long rb_subtree_last;
-	} shared;
+    union {
+        struct {
+            struct rb_node rb;
+            unsigned long rb_subtree_last;
+        } shared;
+        /* Serialized by mmap_sem. */
+        char *anon_name;
+    };
 
 	/*
 	 * A file's MAP_PRIVATE vma can be in both i_mmap tree and anon_vma
@@ -848,4 +854,52 @@ typedef struct {
 	unsigned long val;
 } swp_entry_t;
 
+#ifdef CONFIG_ANON_VMA_NAME
+/*
+ * mmap_lock should be read-locked when calling vma_anon_name() and while using
+ * the returned pointer.
+ */
+extern const char *vma_anon_name(struct vm_area_struct *vma);
+
+/*
+ * mmap_lock should be read-locked for orig_vma->vm_mm.
+ * mmap_lock should be write-locked for new_vma->vm_mm or new_vma should be
+ * isolated.
+ */
+extern void dup_vma_anon_name(struct vm_area_struct *orig_vma,
+                             struct vm_area_struct *new_vma);
+
+/*
+ * mmap_lock should be write-locked or vma should have been isolated under
+ * write-locked mmap_lock protection.
+ */
+extern void free_vma_anon_name(struct vm_area_struct *vma);
+
+/* mmap_lock should be read-locked */
+static inline bool is_same_vma_anon_name(struct vm_area_struct *vma,
+                                        const char *name)
+{
+       const char *vma_name = vma_anon_name(vma);
+
+       /* either both NULL, or pointers to same string */
+       if (vma_name == name)
+               return true;
+
+       return name && vma_name && !strcmp(name, vma_name);
+}
+#else /* CONFIG_ANON_VMA_NAME */
+static inline const char *vma_anon_name(struct vm_area_struct *vma)
+{
+       return NULL;
+}
+static inline void dup_vma_anon_name(struct vm_area_struct *orig_vma,
+                             struct vm_area_struct *new_vma) {}
+static inline void free_vma_anon_name(struct vm_area_struct *vma) {}
+static inline bool is_same_vma_anon_name(struct vm_area_struct *vma,
+                                        const char *name)
+{
+       return true;
+}
+#endif  /* CONFIG_ANON_VMA_NAME */
+
 #endif /* _LINUX_MM_TYPES_H */
diff -uprN a/include/uapi/linux/prctl.h b/include/uapi/linux/prctl.h
--- a/include/uapi/linux/prctl.h	1987-01-06 02:50:02.924000000 +0800
+++ b/include/uapi/linux/prctl.h	1987-01-06 02:53:53.712000000 +0800
@@ -247,4 +247,7 @@ struct prctl_mm_map {
 #define PR_SET_IO_FLUSHER		57
 #define PR_GET_IO_FLUSHER		58
 
+# define PR_SET_VMA             0x53564d41
+# define PR_SET_VMA_ANON_NAME          0
+
 #endif /* _LINUX_PRCTL_H */
diff -uprN a/kernel/cgroup/cgroup.c b/kernel/cgroup/cgroup.c
--- a/kernel/cgroup/cgroup.c	1987-01-06 02:50:02.924000000 +0800
+++ b/kernel/cgroup/cgroup.c	1987-01-06 02:53:53.712000000 +0800
@@ -5974,8 +5974,11 @@ int proc_cgroup_show(struct seq_file *m,
 				retval = -ENAMETOOLONG;
 			if (retval < 0)
 				goto out_unlock;
-
-			seq_puts(m, buf);
+			
+			if(mem_cgroup_from_task(current)->memory.max == PAGE_COUNTER_MAX)
+				seq_puts(m, buf);
+			else
+				seq_puts(m, "/");
 		} else {
 			seq_puts(m, "/");
 		}
diff -uprN a/kernel/fork.c b/kernel/fork.c
--- a/kernel/fork.c	1987-01-06 02:50:02.924000000 +0800
+++ b/kernel/fork.c	1987-01-06 02:53:53.712000000 +0800
@@ -367,12 +367,14 @@ struct vm_area_struct *vm_area_dup(struc
 		*new = data_race(*orig);
 		INIT_LIST_HEAD(&new->anon_vma_chain);
 		new->vm_next = new->vm_prev = NULL;
+		dup_vma_anon_name(orig, new);
 	}
 	return new;
 }
 
 void vm_area_free(struct vm_area_struct *vma)
 {
+	free_vma_anon_name(vma);
 	kmem_cache_free(vm_area_cachep, vma);
 }
 
diff -uprN a/kernel/sys.c b/kernel/sys.c
--- a/kernel/sys.c	1987-01-06 02:50:02.924000000 +0800
+++ b/kernel/sys.c	1987-01-06 02:53:53.712000000 +0800
@@ -2273,6 +2273,66 @@ int __weak arch_prctl_spec_ctrl_set(stru
 
 #define PR_IO_FLUSHER (PF_MEMALLOC_NOIO | PF_LOCAL_THROTTLE)
 
+#ifdef CONFIG_ANON_VMA_NAME
+
+#define ANON_VMA_NAME_MAX_LEN          80
+#define ANON_VMA_NAME_INVALID_CHARS    "\\`$[]"
+
+static inline bool is_valid_name_char(char ch)
+{
+       /* printable ascii characters, excluding ANON_VMA_NAME_INVALID_CHARS */
+       return ch > 0x1f && ch < 0x7f &&
+               !strchr(ANON_VMA_NAME_INVALID_CHARS, ch);
+}
+
+static int prctl_set_vma(unsigned long opt, unsigned long addr,
+                        unsigned long size, unsigned long arg)
+{
+       struct mm_struct *mm = current->mm;
+       const char __user *uname;
+       char *name, *pch;
+       int error;
+
+       switch (opt) {
+       case PR_SET_VMA_ANON_NAME:
+               uname = (const char __user *)arg;
+               if (uname) {
+                       name = strndup_user(uname, ANON_VMA_NAME_MAX_LEN);
+
+                       if (IS_ERR(name))
+                               return PTR_ERR(name);
+
+                       for (pch = name; *pch != '\0'; pch++) {
+                               if (!is_valid_name_char(*pch)) {
+                                       kfree(name);
+                                       return -EINVAL;
+                               }
+                       }
+               } else {
+                       /* Reset the name */
+                       name = NULL;
+               }
+
+               mmap_write_lock(mm);
+               error = madvise_set_anon_name(mm, addr, size, name);
+               mmap_write_unlock(mm);
+               kfree(name);
+               break;
+       default:
+               error = -EINVAL;
+       }
+
+       return error;
+}
+
+#else /* CONFIG_ANON_VMA_NAME */
+static int prctl_set_vma(unsigned long opt, unsigned long start,
+                        unsigned long size, unsigned long arg)
+{
+       return -EINVAL;
+}
+#endif /* CONFIG_ANON_VMA_NAME */
+
 SYSCALL_DEFINE5(prctl, int, option, unsigned long, arg2, unsigned long, arg3,
 		unsigned long, arg4, unsigned long, arg5)
 {
@@ -2523,6 +2583,9 @@ SYSCALL_DEFINE5(prctl, int, option, unsi
 
 		error = (current->flags & PR_IO_FLUSHER) == PR_IO_FLUSHER;
 		break;
+	case PR_SET_VMA:
+		error = prctl_set_vma(arg2, arg3, arg4, arg5);
+		break;
 	default:
 		error = -EINVAL;
 		break;
@@ -2543,6 +2606,20 @@ SYSCALL_DEFINE3(getcpu, unsigned __user
 	return err ? -EFAULT : 0;
 }
 
+static void si_meminfo_cgroup(struct sysinfo *val)
+{
+        struct mem_cgroup *memcg = mem_cgroup_from_task(current);
+
+        val->totalram = memcg->memory.max;
+        val->sharedram = memcg_page_state(memcg, NR_SHMEM);
+        val->freeram = val->totalram - page_counter_read(&memcg->memory);
+        val->bufferram = memcg_page_state(memcg, NR_FILE_PAGES);
+        val->totalhigh = totalhigh_pages();
+        val->freehigh = nr_free_highpages();
+        val->mem_unit = PAGE_SIZE;
+}
+
+
 /**
  * do_sysinfo - fill in sysinfo struct
  * @info: pointer to buffer to fill
@@ -2563,7 +2640,10 @@ static int do_sysinfo(struct sysinfo *in
 
 	info->procs = nr_threads;
 
-	si_meminfo(info);
+	if(mem_cgroup_from_task(current)->memory.max == PAGE_COUNTER_MAX)
+		si_meminfo(info);
+	else
+		si_meminfo_cgroup(info);
 	si_swapinfo(info);
 
 	/*
diff -uprN a/mm/Kconfig b/mm/Kconfig
--- a/mm/Kconfig	1987-01-06 02:50:02.924000000 +0800
+++ b/mm/Kconfig	1987-01-06 02:53:53.712000000 +0800
@@ -969,6 +969,20 @@ config MEMORY_RELIABLE
 	  To enable this function, mirrored memory is needed and
 	  "kernelcore=reliable" need to be added in kernel parameters.
 
+config ANON_VMA_NAME
+    bool "Anonymous VMA name support"
+    depends on PROC_FS && ADVISE_SYSCALLS && MMU
+
+    help
+      Allow naming anonymous virtual memory areas.
+
+      This feature allows assigning names to virtual memory areas. Assigned
+      names can be later retrieved from /proc/pid/maps and /proc/pid/smaps
+      and help identifying individual anonymous memory areas.
+      Assigning a name to anonymous virtual memory area might prevent that
+      area from being merged with adjacent virtual memory areas due to the
+      difference in their name.
+
 source "mm/damon/Kconfig"
 
 endmenu
diff -uprN a/mm/madvise.c b/mm/madvise.c
--- a/mm/madvise.c	1987-01-06 02:50:02.924000000 +0800
+++ b/mm/madvise.c	1987-01-06 02:53:53.716000000 +0800
@@ -18,6 +18,7 @@
 #include <linux/fadvise.h>
 #include <linux/sched.h>
 #include <linux/sched/mm.h>
+#include <linux/string.h>
 #include <linux/uio.h>
 #include <linux/ksm.h>
 #include <linux/fs.h>
@@ -60,83 +61,93 @@ static int madvise_need_mmap_write(int b
 	}
 }
 
+#ifdef CONFIG_ANON_VMA_NAME
+static inline bool has_vma_anon_name(struct vm_area_struct *vma)
+{
+    return !vma->vm_file && vma->anon_name;
+}
+
+const char *vma_anon_name(struct vm_area_struct *vma)
+{
+    if (!has_vma_anon_name(vma))
+        return NULL;
+
+    mmap_assert_locked(vma->vm_mm);
+
+    return vma->anon_name;
+}
+
+void dup_vma_anon_name(struct vm_area_struct *orig_vma,
+                      struct vm_area_struct *new_vma)
+{
+    if (!has_vma_anon_name(orig_vma))
+        return;
+
+    new_vma->anon_name = kstrdup(orig_vma->anon_name, GFP_KERNEL);
+}
+
+void free_vma_anon_name(struct vm_area_struct *vma)
+{
+    if (!has_vma_anon_name(vma))
+        return;
+
+    kfree(vma->anon_name);
+    vma->anon_name = NULL;
+}
+
+/* mmap_lock should be write-locked */
+static int replace_vma_anon_name(struct vm_area_struct *vma, const char *name)
+{
+    if (!name) {
+        free_vma_anon_name(vma);
+        return 0;
+    }
+
+    if (vma->anon_name) {
+        /* Same name, nothing to do here */
+        if (!strcmp(name, vma->anon_name))
+            return 0;
+
+        free_vma_anon_name(vma);
+    }
+    vma->anon_name = kstrdup(name, GFP_KERNEL);
+    if (!vma->anon_name)
+        return -ENOMEM;
+
+    return 0;
+}
+#else /* CONFIG_ANON_VMA_NAME */
+static int replace_vma_anon_name(struct vm_area_struct *vma, const char *name)
+{
+    if (name)
+        return -EINVAL;
+
+    return 0;
+}
+#endif /* CONFIG_ANON_VMA_NAME */
+
 /*
- * We can potentially split a vm area into separate
- * areas, each area with its own behavior.
+ * Update the vm_flags on regiion of a vma, splitting it or merging it as
+ * necessary.  Must be called with mmap_sem held for writing;
  */
-static long madvise_behavior(struct vm_area_struct *vma,
-		     struct vm_area_struct **prev,
-		     unsigned long start, unsigned long end, int behavior)
+static int madvise_update_vma(struct vm_area_struct *vma,
+			                  struct vm_area_struct **prev, unsigned long start,
+			                  unsigned long end, unsigned long new_flags,
+							  const char *name)
 {
 	struct mm_struct *mm = vma->vm_mm;
-	int error = 0;
+	int error;
 	pgoff_t pgoff;
-	unsigned long new_flags = vma->vm_flags;
-
-	switch (behavior) {
-	case MADV_NORMAL:
-		new_flags = new_flags & ~VM_RAND_READ & ~VM_SEQ_READ;
-		break;
-	case MADV_SEQUENTIAL:
-		new_flags = (new_flags & ~VM_RAND_READ) | VM_SEQ_READ;
-		break;
-	case MADV_RANDOM:
-		new_flags = (new_flags & ~VM_SEQ_READ) | VM_RAND_READ;
-		break;
-	case MADV_DONTFORK:
-		new_flags |= VM_DONTCOPY;
-		break;
-	case MADV_DOFORK:
-		if (vma->vm_flags & VM_IO) {
-			error = -EINVAL;
-			goto out;
-		}
-		new_flags &= ~VM_DONTCOPY;
-		break;
-	case MADV_WIPEONFORK:
-		/* MADV_WIPEONFORK is only supported on anonymous memory. */
-		if (vma->vm_file || vma->vm_flags & VM_SHARED) {
-			error = -EINVAL;
-			goto out;
-		}
-		new_flags |= VM_WIPEONFORK;
-		break;
-	case MADV_KEEPONFORK:
-		new_flags &= ~VM_WIPEONFORK;
-		break;
-	case MADV_DONTDUMP:
-		new_flags |= VM_DONTDUMP;
-		break;
-	case MADV_DODUMP:
-		if (!is_vm_hugetlb_page(vma) && new_flags & VM_SPECIAL) {
-			error = -EINVAL;
-			goto out;
-		}
-		new_flags &= ~VM_DONTDUMP;
-		break;
-	case MADV_MERGEABLE:
-	case MADV_UNMERGEABLE:
-		error = ksm_madvise(vma, start, end, behavior, &new_flags);
-		if (error)
-			goto out_convert_errno;
-		break;
-	case MADV_HUGEPAGE:
-	case MADV_NOHUGEPAGE:
-		error = hugepage_madvise(vma, &new_flags, behavior);
-		if (error)
-			goto out_convert_errno;
-		break;
-	}
 
-	if (new_flags == vma->vm_flags) {
+	if (new_flags == vma->vm_flags && is_same_vma_anon_name(vma, name)) {
 		*prev = vma;
-		goto out;
+		return 0;
 	}
 
 	pgoff = vma->vm_pgoff + ((start - vma->vm_start) >> PAGE_SHIFT);
 	*prev = vma_merge(mm, *prev, start, end, new_flags, vma->anon_vma,
 			  vma->vm_file, pgoff, vma_policy(vma),
-			  vma->vm_userfaultfd_ctx);
+			  vma->vm_userfaultfd_ctx, name);
 	if (*prev) {
 		vma = *prev;
 		goto success;
@@ -147,21 +158,21 @@ static long madvise_behavior(struct vm_a
 	if (start != vma->vm_start) {
 		if (unlikely(mm->map_count >= sysctl_max_map_count)) {
 			error = -ENOMEM;
-			goto out;
+			return error;
 		}
 		error = __split_vma(mm, vma, start, 1);
 		if (error)
-			goto out_convert_errno;
+			return error;
 	}
 
 	if (end != vma->vm_end) {
 		if (unlikely(mm->map_count >= sysctl_max_map_count)) {
 			error = -ENOMEM;
-			goto out;
+			return error;
 		}
 		error = __split_vma(mm, vma, end, 0);
 		if (error)
-			goto out_convert_errno;
+			return error;
 	}
 
 success:
@@ -169,16 +180,13 @@ success:
 	 * vm_flags is protected by the mmap_lock held in write mode.
 	 */
 	vma->vm_flags = new_flags;
+    if (!vma->vm_file) {
+        error = replace_vma_anon_name(vma, name);
+        if (error)
+            return error;
+    }
 
-out_convert_errno:
-	/*
-	 * madvise() returns EAGAIN if kernel resources, such as
-	 * slab, are temporarily unavailable.
-	 */
-	if (error == -ENOMEM)
-		error = -EAGAIN;
-out:
-	return error;
+	return 0;
 }
 
 #ifdef CONFIG_SWAP
@@ -870,6 +878,98 @@ static long madvise_remove(struct vm_are
 	return error;
 }
 
+/*
+ * Apply an madvise behavior to a region of a vma.  madvise_update_vma
+ * will handle splitting a vm area into separate areas, each area with its own
+ * behavior.
+ */
+static int madvise_vma_behavior(struct vm_area_struct *vma,
+				struct vm_area_struct **prev,
+				unsigned long start, unsigned long end,
+				unsigned long behavior)
+{
+	int error = 0;
+	unsigned long new_flags = vma->vm_flags;
+
+	switch (behavior) {
+	case MADV_REMOVE:
+		return madvise_remove(vma, prev, start, end);
+	case MADV_WILLNEED:
+		return madvise_willneed(vma, prev, start, end);
+	case MADV_COLD:
+		return madvise_cold(vma, prev, start, end);
+	case MADV_PAGEOUT:
+		return madvise_pageout(vma, prev, start, end);
+	case MADV_FREE:
+	case MADV_DONTNEED:
+		return madvise_dontneed_free(vma, prev, start, end, behavior);
+	case MADV_NORMAL:
+		new_flags = new_flags & ~VM_RAND_READ & ~VM_SEQ_READ;
+		break;
+	case MADV_SEQUENTIAL:
+		new_flags = (new_flags & ~VM_RAND_READ) | VM_SEQ_READ;
+		break;
+	case MADV_RANDOM:
+		new_flags = (new_flags & ~VM_SEQ_READ) | VM_RAND_READ;
+		break;
+	case MADV_DONTFORK:
+		new_flags |= VM_DONTCOPY;
+		break;
+	case MADV_DOFORK:
+		if (vma->vm_flags & VM_IO) {
+			error = -EINVAL;
+			goto out;
+		}
+		new_flags &= ~VM_DONTCOPY;
+		break;
+	case MADV_WIPEONFORK:
+		/* MADV_WIPEONFORK is only supported on anonymous memory. */
+		if (vma->vm_file || vma->vm_flags & VM_SHARED) {
+			error = -EINVAL;
+			goto out;
+		}
+		new_flags |= VM_WIPEONFORK;
+		break;
+	case MADV_KEEPONFORK:
+		new_flags &= ~VM_WIPEONFORK;
+		break;
+	case MADV_DONTDUMP:
+		new_flags |= VM_DONTDUMP;
+		break;
+	case MADV_DODUMP:
+		if (!is_vm_hugetlb_page(vma) && new_flags & VM_SPECIAL) {
+			error = -EINVAL;
+			goto out;
+		}
+		new_flags &= ~VM_DONTDUMP;
+		break;
+	case MADV_MERGEABLE:
+	case MADV_UNMERGEABLE:
+		error = ksm_madvise(vma, start, end, behavior, &new_flags);
+		if (error)
+			goto out;
+		break;
+	case MADV_HUGEPAGE:
+	case MADV_NOHUGEPAGE:
+		error = hugepage_madvise(vma, &new_flags, behavior);
+		if (error)
+			goto out;
+		break;
+	}
+
+	error = madvise_update_vma(vma, prev, start, end, new_flags,
+	                           vma_anon_name(vma));
+
+out:
+	/*
+	 * madvise() returns EAGAIN if kernel resources, such as
+	 * slab, are temporarily unavailable.
+	 */
+	if (error == -ENOMEM)
+		error = -EAGAIN;
+	return error;
+}
+
 #ifdef CONFIG_MEMORY_FAILURE
 /*
  * Error injection support for memory error handling.
@@ -923,6 +1023,7 @@ static int madvise_inject_error(int beha
 }
 #endif
 
+#if 0 //hhc
 static long
 madvise_vma(struct vm_area_struct *vma, struct vm_area_struct **prev,
 		unsigned long start, unsigned long end, int behavior)
@@ -943,6 +1044,7 @@ madvise_vma(struct vm_area_struct *vma,
 		return madvise_behavior(vma, prev, start, end, behavior);
 	}
 }
+#endif
 
 static bool
 madvise_behavior_valid(int behavior)
@@ -982,6 +1084,123 @@ madvise_behavior_valid(int behavior)
 	}
 }
 
+/*
+ * Walk the vmas in range [start,end), and call the visit function on each one.
+ * The visit function will get start and end parameters that cover the overlap
+ * between the current vma and the original range.  Any unmapped regions in the
+ * original range will result in this function returning -ENOMEM while still
+ * calling the visit function on all of the existing vmas in the range.
+ * Must be called with the mmap_lock held for reading or writing.
+ */
+static
+int madvise_walk_vmas(struct mm_struct *mm, unsigned long start,
+		      unsigned long end, unsigned long arg,
+		      int (*visit)(struct vm_area_struct *vma,
+				   struct vm_area_struct **prev, unsigned long start,
+				   unsigned long end, unsigned long arg))
+{
+	struct vm_area_struct *vma;
+	struct vm_area_struct *prev;
+	unsigned long tmp;
+	int unmapped_error = 0;
+
+	/*
+	 * If the interval [start,end) covers some unmapped address
+	 * ranges, just ignore them, but return -ENOMEM at the end.
+	 * - different from the way of handling in mlock etc.
+	 */
+	vma = find_vma_prev(mm, start, &prev);
+	if (vma && start > vma->vm_start)
+		prev = vma;
+
+	for (;;) {
+		int error;
+
+		/* Still start < end. */
+		if (!vma)
+			return -ENOMEM;
+
+		/* Here start < (end|vma->vm_end). */
+		if (start < vma->vm_start) {
+			unmapped_error = -ENOMEM;
+			start = vma->vm_start;
+			if (start >= end)
+				break;
+		}
+
+		/* Here vma->vm_start <= start < (end|vma->vm_end) */
+		tmp = vma->vm_end;
+		if (end < tmp)
+			tmp = end;
+
+		/* Here vma->vm_start <= start < tmp <= (end|vma->vm_end). */
+		error = visit(vma, &prev, start, tmp, arg);
+		if (error)
+			return error;
+		start = tmp;
+		if (prev && start < prev->vm_end)
+			start = prev->vm_end;
+		if (start >= end)
+			break;
+		if (prev)
+			vma = prev->vm_next;
+		else	/* madvise_remove dropped mmap_lock */
+			vma = find_vma(mm, start);
+	}
+
+	return unmapped_error;
+}
+
+#ifdef CONFIG_ANON_VMA_NAME
+static int madvise_vma_anon_name(struct vm_area_struct *vma,
+                                struct vm_area_struct **prev,
+                                unsigned long start, unsigned long end,
+                                unsigned long name)
+{
+    int error;
+
+    /* Only anonymous mappings can be named */
+    if (vma->vm_file)
+        return -EBADF;
+
+    error = madvise_update_vma(vma, prev, start, end, vma->vm_flags,
+                               (const char *)name);
+
+    /*
+     * madvise() returns EAGAIN if kernel resources, such as
+     * slab, are temporarily unavailable.
+     */
+    if (error == -ENOMEM)
+            error = -EAGAIN;
+    return error;
+}
+
+int madvise_set_anon_name(struct mm_struct *mm, unsigned long start,
+                         unsigned long len_in, const char *name)
+{
+    unsigned long end;
+    unsigned long len;
+
+    if (start & ~PAGE_MASK)
+            return -EINVAL;
+    len = (len_in + ~PAGE_MASK) & PAGE_MASK;
+
+    /* Check to see whether len was rounded up from small -ve to zero */
+    if (len_in && !len)
+        return -EINVAL;
+
+    end = start + len;
+    if (end < start)
+        return -EINVAL;
+
+    if (end == start)
+        return 0;
+
+    return madvise_walk_vmas(mm, start, end, (unsigned long)name,
+                             madvise_vma_anon_name);
+}
+#endif /* CONFIG_ANON_VMA_NAME */
+
 static bool
 process_madvise_behavior_valid(int behavior)
 {
@@ -1062,10 +1281,8 @@ process_madvise_behavior_valid(int behav
  */
 int do_madvise(struct mm_struct *mm, unsigned long start, size_t len_in, int behavior)
 {
-	unsigned long end, tmp;
-	struct vm_area_struct *vma, *prev;
-	int unmapped_error = 0;
-	int error = -EINVAL;
+	unsigned long end;
+	int error;
 	int write;
 	size_t len;
 	struct blk_plug plug;
@@ -1073,23 +1290,22 @@ int do_madvise(struct mm_struct *mm, uns
 	start = untagged_addr(start);
 
 	if (!madvise_behavior_valid(behavior))
-		return error;
+		return -EINVAL;
 
 	if (!PAGE_ALIGNED(start))
-		return error;
+		return -EINVAL;
 	len = PAGE_ALIGN(len_in);
 
 	/* Check to see whether len was rounded up from small -ve to zero */
 	if (len_in && !len)
-		return error;
+		return -EINVAL;
 
 	end = start + len;
 	if (end < start)
-		return error;
+		return -EINVAL;
 
-	error = 0;
 	if (end == start)
-		return error;
+		return 0;
 
 #ifdef CONFIG_MEMORY_FAILURE
 	if (behavior == MADV_HWPOISON || behavior == MADV_SOFT_OFFLINE)
@@ -1104,51 +1320,9 @@ int do_madvise(struct mm_struct *mm, uns
 		mmap_read_lock(mm);
 	}
 
-	/*
-	 * If the interval [start,end) covers some unmapped address
-	 * ranges, just ignore them, but return -ENOMEM at the end.
-	 * - different from the way of handling in mlock etc.
-	 */
-	vma = find_vma_prev(mm, start, &prev);
-	if (vma && start > vma->vm_start)
-		prev = vma;
-
 	blk_start_plug(&plug);
-	for (;;) {
-		/* Still start < end. */
-		error = -ENOMEM;
-		if (!vma)
-			goto out;
-
-		/* Here start < (end|vma->vm_end). */
-		if (start < vma->vm_start) {
-			unmapped_error = -ENOMEM;
-			start = vma->vm_start;
-			if (start >= end)
-				goto out;
-		}
-
-		/* Here vma->vm_start <= start < (end|vma->vm_end) */
-		tmp = vma->vm_end;
-		if (end < tmp)
-			tmp = end;
-
-		/* Here vma->vm_start <= start < tmp <= (end|vma->vm_end). */
-		error = madvise_vma(vma, &prev, start, tmp, behavior);
-		if (error)
-			goto out;
-		start = tmp;
-		if (prev && start < prev->vm_end)
-			start = prev->vm_end;
-		error = unmapped_error;
-		if (start >= end)
-			goto out;
-		if (prev)
-			vma = prev->vm_next;
-		else	/* madvise_remove dropped mmap_lock */
-			vma = find_vma(mm, start);
-	}
-out:
+    error = madvise_walk_vmas(mm, start, end, behavior, 
+	                madvise_vma_behavior);
 	blk_finish_plug(&plug);
 	if (write)
 		mmap_write_unlock(mm);
diff -uprN a/mm/memcontrol.c b/mm/memcontrol.c
--- a/mm/memcontrol.c	1987-01-06 02:50:02.924000000 +0800
+++ b/mm/memcontrol.c	1987-01-06 02:53:53.716000000 +0800
@@ -708,7 +708,7 @@ void __mod_memcg_state(struct mem_cgroup
 }
 
 /* idx can be of type enum memcg_stat_item or node_stat_item. */
-static unsigned long memcg_page_state(struct mem_cgroup *memcg, int idx)
+unsigned long memcg_page_state(struct mem_cgroup *memcg, int idx)
 {
 	long x = READ_ONCE(memcg->vmstats.state[idx]);
 #ifdef CONFIG_SMP
diff -uprN a/mm/mempolicy.c b/mm/mempolicy.c
--- a/mm/mempolicy.c	1987-01-06 02:50:02.924000000 +0800
+++ b/mm/mempolicy.c	1987-01-06 02:53:53.716000000 +0800
@@ -872,7 +872,7 @@ static int mbind_range(struct mm_struct
 			((vmstart - vma->vm_start) >> PAGE_SHIFT);
 		prev = vma_merge(mm, prev, vmstart, vmend, vma->vm_flags,
 				 vma->anon_vma, vma->vm_file, pgoff,
-				 new_pol, vma->vm_userfaultfd_ctx);
+				 new_pol, vma->vm_userfaultfd_ctx, vma_anon_name(vma));
 		if (prev) {
 			vma = prev;
 			next = vma->vm_next;
diff -uprN a/mm/mlock.c b/mm/mlock.c
--- a/mm/mlock.c	1987-01-06 02:50:02.924000000 +0800
+++ b/mm/mlock.c	1987-01-06 02:53:53.716000000 +0800
@@ -511,7 +511,7 @@ static int mlock_fixup(struct vm_area_st
 	pgoff = vma->vm_pgoff + ((start - vma->vm_start) >> PAGE_SHIFT);
 	*prev = vma_merge(mm, *prev, start, end, newflags, vma->anon_vma,
 			  vma->vm_file, pgoff, vma_policy(vma),
-			  vma->vm_userfaultfd_ctx);
+			  vma->vm_userfaultfd_ctx, vma_anon_name(vma));
 	if (*prev) {
 		vma = *prev;
 		goto success;
diff -uprN a/mm/mmap.c b/mm/mmap.c
--- a/mm/mmap.c	1987-01-06 02:50:02.924000000 +0800
+++ b/mm/mmap.c	1987-01-06 02:53:53.716000000 +0800
@@ -1037,7 +1037,7 @@ again:
  */
 static inline int is_mergeable_vma(struct vm_area_struct *vma,
 				struct file *file, unsigned long vm_flags,
-				struct vm_userfaultfd_ctx vm_userfaultfd_ctx)
+				struct vm_userfaultfd_ctx vm_userfaultfd_ctx, const char *anon_name)
 {
 	/*
 	 * VM_SOFTDIRTY should not prevent from VMA merging, if we
@@ -1055,6 +1055,8 @@ static inline int is_mergeable_vma(struc
 		return 0;
 	if (!is_mergeable_vm_userfaultfd_ctx(vma, vm_userfaultfd_ctx))
 		return 0;
+    if (!is_same_vma_anon_name(vma, anon_name))
+        return 0;
 	return 1;
 }
 
@@ -1087,9 +1089,10 @@ static int
 can_vma_merge_before(struct vm_area_struct *vma, unsigned long vm_flags,
 		     struct anon_vma *anon_vma, struct file *file,
 		     pgoff_t vm_pgoff,
-		     struct vm_userfaultfd_ctx vm_userfaultfd_ctx)
+		     struct vm_userfaultfd_ctx vm_userfaultfd_ctx,
+			 const char *anon_name)
 {
-	if (is_mergeable_vma(vma, file, vm_flags, vm_userfaultfd_ctx) &&
+	if (is_mergeable_vma(vma, file, vm_flags, vm_userfaultfd_ctx, anon_name) &&
 	    is_mergeable_anon_vma(anon_vma, vma->anon_vma, vma)) {
 		if (vma->vm_pgoff == vm_pgoff)
 			return 1;
@@ -1108,9 +1111,10 @@ static int
 can_vma_merge_after(struct vm_area_struct *vma, unsigned long vm_flags,
 		    struct anon_vma *anon_vma, struct file *file,
 		    pgoff_t vm_pgoff,
-		    struct vm_userfaultfd_ctx vm_userfaultfd_ctx)
+		    struct vm_userfaultfd_ctx vm_userfaultfd_ctx,
+			const char *anon_name)
 {
-	if (is_mergeable_vma(vma, file, vm_flags, vm_userfaultfd_ctx) &&
+	if (is_mergeable_vma(vma, file, vm_flags, vm_userfaultfd_ctx, anon_name) &&
 	    is_mergeable_anon_vma(anon_vma, vma->anon_vma, vma)) {
 		pgoff_t vm_pglen;
 		vm_pglen = vma_pages(vma);
@@ -1168,7 +1172,8 @@ struct vm_area_struct *vma_merge(struct
 			unsigned long end, unsigned long vm_flags,
 			struct anon_vma *anon_vma, struct file *file,
 			pgoff_t pgoff, struct mempolicy *policy,
-			struct vm_userfaultfd_ctx vm_userfaultfd_ctx)
+			struct vm_userfaultfd_ctx vm_userfaultfd_ctx,
+			const char *anon_name)
 {
 	pgoff_t pglen = (end - addr) >> PAGE_SHIFT;
 	struct vm_area_struct *area, *next;
@@ -1202,7 +1207,7 @@ struct vm_area_struct *vma_merge(struct
 			mpol_equal(vma_policy(prev), policy) &&
 			can_vma_merge_after(prev, vm_flags,
 					    anon_vma, file, pgoff,
-					    vm_userfaultfd_ctx)) {
+					    vm_userfaultfd_ctx, anon_name)) {
 		/*
 		 * OK, it can.  Can we now merge in the successor as well?
 		 */
@@ -1211,7 +1216,7 @@ struct vm_area_struct *vma_merge(struct
 				can_vma_merge_before(next, vm_flags,
 						     anon_vma, file,
 						     pgoff+pglen,
-						     vm_userfaultfd_ctx) &&
+						     vm_userfaultfd_ctx, anon_name) &&
 				is_mergeable_anon_vma(prev->anon_vma,
 						      next->anon_vma, NULL)) {
 							/* cases 1, 6 */
@@ -1234,7 +1239,7 @@ struct vm_area_struct *vma_merge(struct
 			mpol_equal(policy, vma_policy(next)) &&
 			can_vma_merge_before(next, vm_flags,
 					     anon_vma, file, pgoff+pglen,
-					     vm_userfaultfd_ctx)) {
+					     vm_userfaultfd_ctx, anon_name)) {
 		if (prev && addr < prev->vm_end)	/* case 4 */
 			err = __vma_adjust(prev, prev->vm_start,
 					 addr, prev->vm_pgoff, NULL, next);
@@ -2022,7 +2027,7 @@ static unsigned long __mmap_region(struc
 	 * Can we just expand an old mapping?
 	 */
 	vma = vma_merge(mm, prev, addr, addr + len, vm_flags,
-			NULL, file, pgoff, NULL, NULL_VM_UFFD_CTX);
+			NULL, file, pgoff, NULL, NULL_VM_UFFD_CTX, NULL);
 	if (vma)
 		goto out;
 
@@ -2081,7 +2086,7 @@ static unsigned long __mmap_region(struc
 		 */
 		if (unlikely(vm_flags != vma->vm_flags && prev)) {
 			merge = vma_merge(mm, prev, vma->vm_start, vma->vm_end, vma->vm_flags,
-				NULL, vma->vm_file, vma->vm_pgoff, NULL, NULL_VM_UFFD_CTX);
+				NULL, vma->vm_file, vma->vm_pgoff, NULL, NULL_VM_UFFD_CTX, NULL);
 			if (merge) {
 				/* ->mmap() can change vma->vm_file and fput the original file. So
 				 * fput the vma->vm_file here or we would add an extra fput for file
@@ -3398,7 +3403,7 @@ static int do_brk_flags(unsigned long ad
 
 	/* Can we just expand an old private anonymous mapping? */
 	vma = vma_merge(mm, prev, addr, addr + len, flags,
-			NULL, NULL, pgoff, NULL, NULL_VM_UFFD_CTX);
+			NULL, NULL, pgoff, NULL, NULL_VM_UFFD_CTX, NULL);
 	if (vma)
 		goto out;
 
@@ -3597,7 +3602,7 @@ struct vm_area_struct *copy_vma(struct v
 		return NULL;	/* should never get here */
 	new_vma = vma_merge(mm, prev, addr, addr + len, vma->vm_flags,
 			    vma->anon_vma, vma->vm_file, pgoff, vma_policy(vma),
-			    vma->vm_userfaultfd_ctx);
+			    vma->vm_userfaultfd_ctx, vma_anon_name(vma));
 	if (new_vma) {
 		/*
 		 * Source vma may have been merged into new_vma
diff -uprN a/mm/mprotect.c b/mm/mprotect.c
--- a/mm/mprotect.c	1987-01-06 02:50:02.924000000 +0800
+++ b/mm/mprotect.c	1987-01-06 02:53:53.716000000 +0800
@@ -454,7 +454,7 @@ mprotect_fixup(struct vm_area_struct *vm
 	pgoff = vma->vm_pgoff + ((start - vma->vm_start) >> PAGE_SHIFT);
 	*pprev = vma_merge(mm, *pprev, start, end, newflags,
 			   vma->anon_vma, vma->vm_file, pgoff, vma_policy(vma),
-			   vma->vm_userfaultfd_ctx);
+			   vma->vm_userfaultfd_ctx, vma_anon_name(vma));
 	if (*pprev) {
 		vma = *pprev;
 		VM_WARN_ON((vma->vm_flags ^ newflags) & ~VM_SOFTDIRTY);
